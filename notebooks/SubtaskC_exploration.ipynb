{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from lib.utils import get_device, get_current_date\n",
    "from lib.utils.constants import Subtask, Track, PreprocessTextLevel, DatasetType\n",
    "from lib.utils.models import sequential_fully_connected\n",
    "from lib.data.loading import load_train_dev_test_df\n",
    "from lib.data.tokenizer import get_tokenizer\n",
    "from lib.training.optimizer import get_optimizer, get_scheduler\n",
    "from lib.training.loss import get_loss_fn\n",
    "from lib.training.metric import get_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE_PATH = os.path.relpath(\"../config.json\")\n",
    "\n",
    "config = {}\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Track not specified in config for subtask: Subtask.SubtaskC\n",
      "Loading train data...\n",
      "Train/dev split... (df_train.shape: (3649, 3))\n",
      "Loading test data....././data/original_data/SubtaskC/SubtaskC_dev.jsonl\n",
      "df_train.shape: (2919, 3)\n",
      "df_dev.shape: (730, 3)\n",
      "df_test.shape: (505, 3)\n"
     ]
    }
   ],
   "source": [
    "task = None\n",
    "if \"task\" in config:\n",
    "    task = Subtask(config[\"task\"])\n",
    "else:\n",
    "    raise ValueError(\"Task not specified in config\")\n",
    "\n",
    "track = None\n",
    "if \"track\" in config:\n",
    "    track = Track(config[\"track\"])\n",
    "else:\n",
    "    print(f\"Warning: Track not specified in config for subtask: {task}\")\n",
    "\n",
    "dataset_type = DatasetType.TransformerTruncationDataset\n",
    "if \"dataset_type\" in config[\"data\"]:\n",
    "    dataset_type = DatasetType(config[\"data\"][\"dataset_type\"])\n",
    "\n",
    "dataset_type_settings = None\n",
    "if \"dataset_type_settings\" in config[\"data\"]:\n",
    "    dataset_type_settings = config[\"data\"][\"dataset_type_settings\"]\n",
    "\n",
    "df_train, df_dev, df_test = load_train_dev_test_df(\n",
    "    task=task,\n",
    "    track=track,\n",
    "    data_dir=f\"../{config['data']['data_dir']}\",\n",
    "    label_column=config[\"data\"][\"label_column\"],\n",
    "    test_size=config[\"data\"][\"test_size\"],\n",
    "    preprocess_text_level=PreprocessTextLevel(\n",
    "        config[\"data\"][\"preprocess_text_level\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"df_train.shape: {df_train.shape}\")\n",
    "print(f\"df_dev.shape: {df_dev.shape}\")\n",
    "print(f\"df_test.shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save results to: ../runs/29-12-2023_13:52:52-SubtaskC-longformer\n"
     ]
    }
   ],
   "source": [
    "results_dir = os.path.relpath(\n",
    "    f\"../runs/{get_current_date()}-{task.value}-{config['model']}\"\n",
    ")\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "print(f\"Will save results to: {results_dir}\")\n",
    "\n",
    "with open(results_dir + \"/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "class TokenClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ids: np.ndarray,\n",
    "        texts: np.ndarray,\n",
    "        targets: np.ndarray | None,\n",
    "        tokenizer: PreTrainedTokenizer | None,\n",
    "        max_len: int,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if tokenizer is None:\n",
    "            raise ValueError(\"Tokenizer cannot be None\")\n",
    "\n",
    "        self.ids = ids\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item_id = self.ids[index]\n",
    "        text = self.texts[index]\n",
    "        target = -1 if self.targets is None else self.targets[index]\n",
    "        targets_available = False if target == -1 else True\n",
    "\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\r\", \" \")\n",
    "\n",
    "        words = [w for w in text.split(\" \") if w != \"\"]\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Words: {words}\")\n",
    "            print(f\"Machine text start position: {target}\")\n",
    "            print()\n",
    "\n",
    "        targets = []\n",
    "        corresponding_word = []\n",
    "        tokens = []\n",
    "        input_ids = []\n",
    "        attention_mask = []\n",
    "\n",
    "        for idx, word in enumerate(words):\n",
    "            word_encoded = self.tokenizer.tokenize(word)  # No [CLS] or [SEP]\n",
    "            sub_words = len(word_encoded)\n",
    "\n",
    "            if targets_available:\n",
    "                is_machine_text = 1 if idx >= target else 0\n",
    "                targets.extend([is_machine_text] * sub_words)\n",
    "\n",
    "            corresponding_word.extend([idx] * sub_words)\n",
    "            tokens.extend(word_encoded)\n",
    "            input_ids.extend(self.tokenizer.convert_tokens_to_ids(word_encoded))\n",
    "            attention_mask.extend([1] * sub_words)\n",
    "\n",
    "            if self.debug:\n",
    "                print(\n",
    "                    f\"word[{idx}]:\\n\"\n",
    "                    f\"{'':-<5}> tokens: {word_encoded} (no. of subwords: {sub_words})\\n\"\n",
    "                    f\"{'':-<5}> corresponding_word: {corresponding_word[-sub_words:]}\\n\"\n",
    "                    f\"{'':-<5}> input_ids: {input_ids[-sub_words:]}\\n\"\n",
    "                    f\"{'':-<5}> is_machine_text: {is_machine_text}\"\n",
    "                )\n",
    "\n",
    "        if self.debug:\n",
    "            print()\n",
    "\n",
    "            print(f\"corresponding_word: {corresponding_word}\")\n",
    "            print(f\"tokens: {tokens}\")\n",
    "            print(f\"input_ids: {input_ids}\")\n",
    "            print(f\"attention_mask: {attention_mask}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "            print(f\"Machine text start word: {words[corresponding_word[targets.index(1)]]}\")\n",
    "            print(f\"True machine text start word: {words[target]}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "        if len(input_ids) < self.max_len - 2:\n",
    "            if targets_available:\n",
    "                targets = (\n",
    "                    [-100]\n",
    "                    + targets\n",
    "                    + [-100] * (self.max_len - len(input_ids) - 1)\n",
    "                )\n",
    "\n",
    "            corresponding_word = (\n",
    "                [-100]\n",
    "                + corresponding_word\n",
    "                + [-100] * (self.max_len - len(input_ids) - 1)\n",
    "            )\n",
    "            tokens = (\n",
    "                [self.tokenizer.bos_token]\n",
    "                + tokens\n",
    "                + [self.tokenizer.eos_token]\n",
    "                + [self.tokenizer.pad_token] * (self.max_len - len(tokens) - 2)\n",
    "            )\n",
    "            input_ids = (\n",
    "                [self.tokenizer.bos_token_id]\n",
    "                + input_ids\n",
    "                + [self.tokenizer.eos_token_id]\n",
    "                + [self.tokenizer.pad_token_id] * (self.max_len - len(input_ids) - 2)\n",
    "            )\n",
    "            attention_mask = (\n",
    "                [1]\n",
    "                + attention_mask\n",
    "                + [1]\n",
    "                + [0] * (self.max_len - len(attention_mask) - 2)\n",
    "            )\n",
    "        else:\n",
    "            if targets_available:\n",
    "                targets = [-100] + targets[: self.max_len - 2] + [-100]\n",
    "\n",
    "            corresponding_word = (\n",
    "                [-100]\n",
    "                + corresponding_word[: self.max_len - 2]\n",
    "                + [-100]\n",
    "            )\n",
    "            tokens = (\n",
    "                [self.tokenizer.bos_token]\n",
    "                + tokens[: self.max_len - 2]\n",
    "                + [self.tokenizer.eos_token]\n",
    "            )\n",
    "            input_ids = (\n",
    "                [self.tokenizer.bos_token_id]\n",
    "                + input_ids[: self.max_len - 2]\n",
    "                + [self.tokenizer.eos_token_id]\n",
    "            )\n",
    "            attention_mask = (\n",
    "                [1]\n",
    "                + attention_mask[: self.max_len - 2]\n",
    "                + [1]\n",
    "            )\n",
    "\n",
    "        encoded = {}\n",
    "        encoded[\"id\"] = item_id\n",
    "        encoded[\"text\"] = text\n",
    "        encoded[\"true_target\"] = torch.tensor(target)\n",
    "        encoded[\"corresponding_word\"] = torch.tensor(corresponding_word)\n",
    "        encoded[\"input_ids\"] = torch.tensor(input_ids)\n",
    "        encoded[\"attention_mask\"] = torch.tensor(attention_mask)\n",
    "        if targets_available:\n",
    "            encoded[\"target\"] = torch.tensor(targets)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Tokenized human position: {targets.index(1)}\")\n",
    "            print(f\"Original human position: {target}\")\n",
    "            print(f\"Full human text: {text}\\n\\n\")\n",
    "            print(f\"Human truncated text: {[w for w in text.split(' ')[:target] if w != '']}\\n\\n\")\n",
    "\n",
    "            encoded[\"partial_human_review\"] = \" \".join(\n",
    "                [w for w in text.split(' ')[:target] if w != '']\n",
    "            )\n",
    "\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = get_tokenizer(**config[\"tokenizer\"])\n",
    "\n",
    "train_dataset = TokenClassificationDataset(\n",
    "    ids=df_train[\"id\"].values,\n",
    "    texts=df_train[\"text\"].values,\n",
    "    targets=df_train[\"label\"].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "dev_dataset = TokenClassificationDataset(\n",
    "    ids=df_dev[\"id\"].values,\n",
    "    texts=df_dev[\"text\"].values,\n",
    "    targets=df_dev[\"label\"].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "test_dataset = TokenClassificationDataset(\n",
    "    ids=df_test[\"id\"].values,\n",
    "    texts=df_test[\"text\"].values,\n",
    "    targets=df_test[\"label\"].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "dev_dataloader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(train_dataloader):\n",
    "#     print(f\"Batch=[{i + 1}/{len(train_dataloader)}]\")\n",
    "#     # break\n",
    "\n",
    "# for i, batch in enumerate(dev_dataloader):\n",
    "#     print(f\"Batch=[{i + 1}/{len(dev_dataloader)}]\")\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Longformer model for token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import LongformerModel\n",
    "\n",
    "\n",
    "class LongformerForTokenClassification(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model_name,\n",
    "        out_size,\n",
    "        device,\n",
    "        dropout_p=0.3,\n",
    "        fc=[],\n",
    "        finetune_last_transformer_layers=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_size = out_size\n",
    "        self.device = device\n",
    "        self.finetune_last_transformer_layers = finetune_last_transformer_layers\n",
    "\n",
    "        self.longformer = LongformerModel.from_pretrained(\n",
    "            pretrained_model_name, return_dict=False\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        # self.classifier = nn.Linear(self.longformer.config.hidden_size, out_size)\n",
    "        self.classifier = sequential_fully_connected(\n",
    "            self.longformer.config.hidden_size, out_size, fc, dropout_p\n",
    "        )\n",
    "\n",
    "        self.freeze_transformer_layer()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        sequence_output, _ = self.longformer(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss().to(self.device)\n",
    "            loss = loss_fn(logits.view(-1, self.out_size), labels.view(-1))\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "    def freeze_transformer_layer(self):\n",
    "        for param in self.longformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_transformer_layer(self):\n",
    "        if self.finetune_last_transformer_layers is not None:\n",
    "            # Fine-tune only the last selected layer\n",
    "            for layer in self.longformer.encoder.layer[-self.finetune_last_transformer_layers :]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "        else:\n",
    "            # No fine-tuning\n",
    "            pass\n",
    "\n",
    "    def get_predictions_from_logits(self, logits, labels=None, corresponding_word=None):\n",
    "        batch_size = logits.shape[0]\n",
    "\n",
    "        # logits: (batch_size, max_seq_len, out_size)\n",
    "        # labels: (batch_size, max_seq_len)\n",
    "        # corresponding_word: (batch_size, max_seq_len)\n",
    "\n",
    "        # print(f\"logits.shape: {logits.shape}\")\n",
    "        # print(f\"logits: {logits}\")\n",
    "\n",
    "        # preds: (batch_size, max_seq_len)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # print(f\"preds.shape: {preds.shape}\")\n",
    "        # print(f\"preds: {preds}\")\n",
    "\n",
    "        if labels is not None:\n",
    "            # print(f\"labels.shape: {labels.shape}\")\n",
    "            # print(f\"labels: {labels}\")\n",
    "\n",
    "            # Keep only predictions where labels are not -100\n",
    "            # clean_preds = preds[labels != -100].reshape(batch_size, -1)\n",
    "            # clean_labels = labels[labels != -100].reshape(batch_size, -1)\n",
    "\n",
    "            # print(f\"clean_preds.shape: {clean_preds.shape}\")\n",
    "            # print(f\"clean_preds: {clean_preds}\")\n",
    "\n",
    "            # print(f\"clean_labels.shape: {clean_labels.shape}\")\n",
    "            # print(f\"clean_labels: {clean_labels}\")\n",
    "\n",
    "            # Get the index of the first machine text word\n",
    "            # predicted_positions = clean_preds.argmax(dim=-1)\n",
    "            # true_positions = clean_labels.argmax(dim=-1)\n",
    "\n",
    "            predicted_positions = []\n",
    "            true_positions = []\n",
    "            for p, l in zip(preds, labels):\n",
    "                mask = l != -100\n",
    "\n",
    "                clean_pred = p[mask]\n",
    "                clean_label = l[mask]\n",
    "\n",
    "                # print(f\"clean_pred.shape: {clean_pred.shape}\")\n",
    "                # print(f\"clean_pred: {clean_pred}\")\n",
    "                # print(f\"clean_label.shape: {clean_label.shape}\")\n",
    "                # print(f\"clean_label: {clean_label}\")\n",
    "\n",
    "                predicted_position = clean_pred.argmax(dim=-1)\n",
    "                true_position = clean_label.argmax(dim=-1)\n",
    "\n",
    "                # print(f\"predicted_position: {predicted_position}\")\n",
    "                # print(f\"true_position: {true_position}\")\n",
    "\n",
    "                predicted_positions.append(predicted_position.item())\n",
    "                true_positions.append(true_position.item())\n",
    "\n",
    "            # print(f\"predicted_positions.shape: {predicted_positions.shape}\")\n",
    "            # print(f\"predicted_positions: {predicted_positions}\")\n",
    "\n",
    "            # print(f\"true_positions.shape: {true_positions.shape}\")\n",
    "            # print(f\"true_positions: {true_positions}\")\n",
    "\n",
    "            # print(f\"predicted_positions type: {type(predicted_positions)}\")\n",
    "            # print(f\"true_positions type: {type(true_positions)}\")\n",
    "\n",
    "            return torch.Tensor(predicted_positions), torch.Tensor(true_positions)\n",
    "        elif corresponding_word is not None:\n",
    "            # print(f\"corresponding_word.shape: {corresponding_word.shape}\")\n",
    "            # print(f\"corresponding_word: {corresponding_word}\")\n",
    "\n",
    "            # Keep only predictions where corresponding_word are not -100\n",
    "            # clean_preds = preds[corresponding_word != -100].reshape(\n",
    "            #     batch_size, -1\n",
    "            # ).detach().cpu().numpy()\n",
    "            # clean_corresponding_word = corresponding_word[corresponding_word != -100].reshape(\n",
    "            #     batch_size, -1\n",
    "            # ).detach().cpu().numpy()\n",
    "\n",
    "            # print(f\"clean_preds.shape: {clean_preds.shape}\")\n",
    "            # print(f\"clean_preds: {clean_preds}\")\n",
    "\n",
    "            # print(f\"clean_corresponding_word.shape: {clean_corresponding_word.shape}\")\n",
    "            # print(f\"clean_corresponding_word: {clean_corresponding_word}\")\n",
    "\n",
    "            predicted_positions = []\n",
    "            for p, w in zip(preds, corresponding_word):\n",
    "                mask = w != -100\n",
    "\n",
    "                clean_pred = p[mask]\n",
    "                clean_corresponding_word = w[mask]\n",
    "\n",
    "                # print(f\"clean_pred.shape: {clean_pred.shape}\")\n",
    "                # print(f\"clean_pred: {clean_pred}\")\n",
    "                # print(f\"clean_corresponding_word.shape: {clean_corresponding_word.shape}\")\n",
    "                # print(f\"clean_corresponding_word: {clean_corresponding_word}\")\n",
    "\n",
    "                # Get the index of the first machine text word\n",
    "                index = torch.where(clean_pred == 1)[0]\n",
    "                value = index[0] if index.size else len(clean_pred) - 1\n",
    "                position = clean_corresponding_word[value]\n",
    "\n",
    "                # print(f\"index: {index}\")\n",
    "                # print(f\"value: {value}\")\n",
    "                # print(f\"position: {position}\")\n",
    "\n",
    "                predicted_positions.append(position.item())\n",
    "            #     # pred = pred.detach().cpu().numpy()\n",
    "\n",
    "            #     index = np.where(pred == 1)[0]\n",
    "            #     value = index[0] if index.size else len(pred) - 1\n",
    "            #     position = clean_corresponding_word[idx][value]\n",
    "\n",
    "            #     predicted_positions.append(position.item())\n",
    "\n",
    "            print(f\"predicted_positions: {predicted_positions}\")\n",
    "\n",
    "            return predicted_positions, None\n",
    "        else:\n",
    "            raise ValueError(\"Either labels or corresponding_word must be provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    metric_fn,\n",
    "    print_freq=10,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        ids = batch[\"id\"]\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"target\"].to(device)\n",
    "        corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "        loss, logits = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=targets,\n",
    "        )\n",
    "\n",
    "        predictions, true_predictions = model.get_predictions_from_logits(\n",
    "            logits=logits,\n",
    "            labels=targets,\n",
    "            corresponding_word=corresponding_word\n",
    "        )\n",
    "\n",
    "        # print(f\"predictions: {predictions}\")\n",
    "        # print(f\"true_predictions: {true_predictions}\")\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        all_predictions.extend(predictions.tolist())\n",
    "        all_true.extend(true_predictions.tolist())\n",
    "        all_ids.extend(ids)\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(\n",
    "                f\"Batch [{i + 1}/{len(dataloader)}]; \"\n",
    "                f\"Loss: {loss.item():.5f}; \"\n",
    "                f\"Mean absolute error: {metric_fn(true_predictions, predictions):.5f}\"\n",
    "            )\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return np.mean(losses), (all_ids, all_true, all_predictions)\n",
    "\n",
    "\n",
    "def validation_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    metric_fn,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            ids = batch[\"id\"]\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "            corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "            loss, logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=targets,\n",
    "            )\n",
    "\n",
    "            predictions, true_predictions = model.get_predictions_from_logits(\n",
    "                logits=logits,\n",
    "                labels=targets,\n",
    "                corresponding_word=corresponding_word\n",
    "            )\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            all_true.extend(true_predictions.tolist())\n",
    "            all_ids.extend(ids)\n",
    "\n",
    "    return np.mean(losses), (all_ids, all_true, all_predictions)\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer_config,\n",
    "    scheduler_config,\n",
    "    device,\n",
    "    metric_fn,\n",
    "    is_better_metric_fn,\n",
    "    num_epochs_before_finetune,\n",
    "    results_dir,\n",
    "):\n",
    "    history = defaultdict(list)\n",
    "    best_metric = None\n",
    "    best_model_state = None\n",
    "\n",
    "    optimizer = get_optimizer(model, optimizer_config, finetune=False)\n",
    "    scheduler = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        if epoch <= num_epochs_before_finetune:\n",
    "            print(\"Freeze transformer\")\n",
    "        else:\n",
    "            print(\"Finetune transformer\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        if epoch == num_epochs_before_finetune + 1:\n",
    "            model.unfreeze_transformer_layer()\n",
    "            optimizer = get_optimizer(model, optimizer_config, finetune=True)\n",
    "            scheduler = get_scheduler(\n",
    "                optimizer,\n",
    "                num_training_steps=len(train_dataloader) * num_epochs,\n",
    "                **scheduler_config,\n",
    "            )\n",
    "\n",
    "        train_loss, (train_ids, train_true, train_predict) = train_epoch(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            device,\n",
    "            scheduler,\n",
    "            metric_fn,\n",
    "        )\n",
    "\n",
    "        train_metric = metric_fn(train_true, train_predict)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.5f}; Train Metric: {train_metric:.5f}\")\n",
    "\n",
    "        dev_loss, (dev_ids, dev_true, dev_predict) = validation_epoch(\n",
    "            model,\n",
    "            dev_dataloader,\n",
    "            loss_fn,\n",
    "            device,\n",
    "            metric_fn,\n",
    "        )\n",
    "\n",
    "        dev_metric = metric_fn(dev_true, dev_predict)\n",
    "\n",
    "        print(\n",
    "            f\"Validation Loss: {dev_loss:.5f}; \"\n",
    "            f\"Validation Metric: {dev_metric:.5f}\"\n",
    "        )\n",
    "\n",
    "        history[\"train_metric\"].append(train_metric)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"dev_metric\"].append(dev_metric)\n",
    "        history[\"dev_loss\"].append(dev_loss)\n",
    "\n",
    "        if best_metric is None or is_better_metric_fn(train_metric, best_metric):\n",
    "            best_metric = train_metric\n",
    "            best_model_state = model.state_dict()\n",
    "            \n",
    "            if results_dir is not None:\n",
    "                torch.save(\n",
    "                    best_model_state,\n",
    "                    os.path.join(results_dir, \"best_model.bin\"),\n",
    "                )\n",
    "\n",
    "                df_train_predictions = pd.DataFrame(\n",
    "                    {\n",
    "                        \"id\": train_ids,\n",
    "                        \"true\": train_true,\n",
    "                        \"predict\": train_predict,\n",
    "                    }\n",
    "                )\n",
    "                df_train_predictions.to_csv(\n",
    "                    os.path.join(results_dir, \"best_model_train_predict.csv\"),\n",
    "                    index=False\n",
    "                )\n",
    "\n",
    "                df_dev_predictions = pd.DataFrame(\n",
    "                    {\n",
    "                        \"id\": dev_ids,\n",
    "                        \"true\": dev_true,\n",
    "                        \"predict\": dev_predict,\n",
    "                    }\n",
    "                )\n",
    "                df_dev_predictions.to_csv(\n",
    "                    os.path.join(results_dir, \"best_model_dev_predict.csv\"),\n",
    "                    index=False\n",
    "                )\n",
    "\n",
    "    df_history = pd.DataFrame(history)\n",
    "    if results_dir is not None:\n",
    "        df_history.to_csv(os.path.join(results_dir, \"history.csv\"), index=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(results_dir, \"best_model.bin\")))\n",
    "    else:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model, df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.76302; Mean absolute error: 82.15625\n",
      "Batch [11/92]; Loss: 0.46320; Mean absolute error: 115.59375\n",
      "Batch [21/92]; Loss: 0.34986; Mean absolute error: 82.84375\n",
      "Batch [31/92]; Loss: 0.37145; Mean absolute error: 100.75000\n",
      "Batch [41/92]; Loss: 0.26759; Mean absolute error: 37.84375\n",
      "Batch [51/92]; Loss: 0.21389; Mean absolute error: 30.50000\n",
      "Batch [61/92]; Loss: 0.19438; Mean absolute error: 47.50000\n",
      "Batch [71/92]; Loss: 0.17723; Mean absolute error: 40.12500\n",
      "Batch [81/92]; Loss: 0.22333; Mean absolute error: 35.50000\n",
      "Batch [91/92]; Loss: 0.22262; Mean absolute error: 62.15625\n",
      "Train Loss: 0.31289; Train Metric: 62.22097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.21862; Validation Metric: 56.70274\n",
      "Epoch 2/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.17524; Mean absolute error: 49.00000\n",
      "Batch [11/92]; Loss: 0.13358; Mean absolute error: 44.43750\n",
      "Batch [21/92]; Loss: 0.16321; Mean absolute error: 48.03125\n",
      "Batch [31/92]; Loss: 0.15178; Mean absolute error: 13.09375\n",
      "Batch [41/92]; Loss: 0.17794; Mean absolute error: 49.84375\n",
      "Batch [51/92]; Loss: 0.14278; Mean absolute error: 30.06250\n",
      "Batch [61/92]; Loss: 0.13054; Mean absolute error: 35.62500\n",
      "Batch [71/92]; Loss: 0.16738; Mean absolute error: 34.53125\n",
      "Batch [81/92]; Loss: 0.14050; Mean absolute error: 20.96875\n",
      "Batch [91/92]; Loss: 0.12654; Mean absolute error: 27.43750\n",
      "Train Loss: 0.16130; Train Metric: 36.77629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:33<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.19880; Validation Metric: 54.62055\n",
      "Epoch 3/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.27001; Mean absolute error: 53.65625\n",
      "Batch [11/92]; Loss: 0.13337; Mean absolute error: 18.46875\n",
      "Batch [21/92]; Loss: 0.11059; Mean absolute error: 26.68750\n",
      "Batch [31/92]; Loss: 0.15157; Mean absolute error: 39.84375\n",
      "Batch [41/92]; Loss: 0.16813; Mean absolute error: 39.56250\n",
      "Batch [51/92]; Loss: 0.12590; Mean absolute error: 25.06250\n",
      "Batch [61/92]; Loss: 0.11788; Mean absolute error: 20.12500\n",
      "Batch [71/92]; Loss: 0.12131; Mean absolute error: 21.43750\n",
      "Batch [81/92]; Loss: 0.09903; Mean absolute error: 31.59375\n",
      "Batch [91/92]; Loss: 0.10665; Mean absolute error: 28.93750\n",
      "Train Loss: 0.12589; Train Metric: 31.53409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.14984; Validation Metric: 36.58356\n",
      "Epoch 4/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.08819; Mean absolute error: 29.40625\n",
      "Batch [11/92]; Loss: 0.13180; Mean absolute error: 38.46875\n",
      "Batch [21/92]; Loss: 0.11297; Mean absolute error: 38.31250\n",
      "Batch [31/92]; Loss: 0.09610; Mean absolute error: 35.62500\n",
      "Batch [41/92]; Loss: 0.10150; Mean absolute error: 48.43750\n",
      "Batch [51/92]; Loss: 0.07691; Mean absolute error: 13.03125\n",
      "Batch [61/92]; Loss: 0.11810; Mean absolute error: 28.06250\n",
      "Batch [71/92]; Loss: 0.09224; Mean absolute error: 26.34375\n",
      "Batch [81/92]; Loss: 0.09174; Mean absolute error: 51.37500\n",
      "Batch [91/92]; Loss: 0.14927; Mean absolute error: 35.43750\n",
      "Train Loss: 0.10615; Train Metric: 27.58890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.17924; Validation Metric: 43.50822\n",
      "Epoch 5/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.08286; Mean absolute error: 22.12500\n",
      "Batch [11/92]; Loss: 0.10223; Mean absolute error: 34.68750\n",
      "Batch [21/92]; Loss: 0.07683; Mean absolute error: 30.78125\n",
      "Batch [31/92]; Loss: 0.09310; Mean absolute error: 24.75000\n",
      "Batch [41/92]; Loss: 0.06797; Mean absolute error: 19.62500\n",
      "Batch [51/92]; Loss: 0.08766; Mean absolute error: 15.31250\n",
      "Batch [61/92]; Loss: 0.09032; Mean absolute error: 15.53125\n",
      "Batch [71/92]; Loss: 0.08137; Mean absolute error: 18.71875\n",
      "Batch [81/92]; Loss: 0.07043; Mean absolute error: 20.56250\n",
      "Batch [91/92]; Loss: 0.09951; Mean absolute error: 37.50000\n",
      "Train Loss: 0.08908; Train Metric: 24.55807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:33<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.15607; Validation Metric: 42.32603\n",
      "Epoch 6/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.06328; Mean absolute error: 33.40625\n",
      "Batch [11/92]; Loss: 0.06895; Mean absolute error: 10.87500\n",
      "Batch [21/92]; Loss: 0.07522; Mean absolute error: 19.28125\n",
      "Batch [31/92]; Loss: 0.07822; Mean absolute error: 32.53125\n",
      "Batch [41/92]; Loss: 0.08720; Mean absolute error: 28.96875\n",
      "Batch [51/92]; Loss: 0.05649; Mean absolute error: 16.84375\n",
      "Batch [61/92]; Loss: 0.08846; Mean absolute error: 22.43750\n",
      "Batch [71/92]; Loss: 0.08206; Mean absolute error: 18.96875\n",
      "Batch [81/92]; Loss: 0.08086; Mean absolute error: 22.12500\n",
      "Batch [91/92]; Loss: 0.06019; Mean absolute error: 10.78125\n",
      "Train Loss: 0.08154; Train Metric: 23.18876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:33<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.19502; Validation Metric: 48.83014\n",
      "Epoch 7/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.07055; Mean absolute error: 17.31250\n",
      "Batch [11/92]; Loss: 0.08775; Mean absolute error: 19.93750\n",
      "Batch [21/92]; Loss: 0.06973; Mean absolute error: 19.93750\n",
      "Batch [31/92]; Loss: 0.06682; Mean absolute error: 13.90625\n",
      "Batch [41/92]; Loss: 0.18191; Mean absolute error: 23.75000\n",
      "Batch [51/92]; Loss: 0.06371; Mean absolute error: 17.18750\n",
      "Batch [61/92]; Loss: 0.07259; Mean absolute error: 22.40625\n",
      "Batch [71/92]; Loss: 0.06994; Mean absolute error: 24.96875\n",
      "Batch [81/92]; Loss: 0.06209; Mean absolute error: 21.15625\n",
      "Batch [91/92]; Loss: 0.09621; Mean absolute error: 38.28125\n",
      "Train Loss: 0.07174; Train Metric: 21.18911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:33<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.16522; Validation Metric: 41.18356\n",
      "Epoch 8/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.04836; Mean absolute error: 22.03125\n",
      "Batch [11/92]; Loss: 0.07243; Mean absolute error: 30.62500\n",
      "Batch [21/92]; Loss: 0.06197; Mean absolute error: 15.62500\n",
      "Batch [31/92]; Loss: 0.06687; Mean absolute error: 26.43750\n",
      "Batch [41/92]; Loss: 0.06365; Mean absolute error: 18.75000\n",
      "Batch [51/92]; Loss: 0.07276; Mean absolute error: 19.09375\n",
      "Batch [61/92]; Loss: 0.07056; Mean absolute error: 41.68750\n",
      "Batch [71/92]; Loss: 0.07366; Mean absolute error: 25.37500\n",
      "Batch [81/92]; Loss: 0.07042; Mean absolute error: 58.43750\n",
      "Batch [91/92]; Loss: 0.06648; Mean absolute error: 12.28125\n",
      "Train Loss: 0.06498; Train Metric: 20.25180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:33<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20087; Validation Metric: 46.74521\n",
      "Epoch 9/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.06884; Mean absolute error: 23.93750\n",
      "Batch [11/92]; Loss: 0.06013; Mean absolute error: 20.25000\n",
      "Batch [21/92]; Loss: 0.04884; Mean absolute error: 28.21875\n",
      "Batch [31/92]; Loss: 0.04481; Mean absolute error: 14.75000\n",
      "Batch [41/92]; Loss: 0.05929; Mean absolute error: 17.59375\n",
      "Batch [51/92]; Loss: 0.06312; Mean absolute error: 24.87500\n",
      "Batch [61/92]; Loss: 0.05826; Mean absolute error: 31.71875\n",
      "Batch [71/92]; Loss: 0.05898; Mean absolute error: 14.50000\n",
      "Batch [81/92]; Loss: 0.05769; Mean absolute error: 21.00000\n",
      "Batch [91/92]; Loss: 0.05935; Mean absolute error: 18.56250\n",
      "Train Loss: 0.05953; Train Metric: 19.67729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:33<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.17147; Validation Metric: 41.07260\n",
      "Epoch 10/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.05266; Mean absolute error: 18.00000\n",
      "Batch [11/92]; Loss: 0.05244; Mean absolute error: 8.78125\n",
      "Batch [21/92]; Loss: 0.05830; Mean absolute error: 32.81250\n",
      "Batch [31/92]; Loss: 0.04644; Mean absolute error: 18.50000\n",
      "Batch [41/92]; Loss: 0.05483; Mean absolute error: 19.65625\n",
      "Batch [51/92]; Loss: 0.04915; Mean absolute error: 19.15625\n",
      "Batch [61/92]; Loss: 0.05381; Mean absolute error: 15.78125\n",
      "Batch [71/92]; Loss: 0.05651; Mean absolute error: 15.43750\n",
      "Batch [81/92]; Loss: 0.05259; Mean absolute error: 13.65625\n",
      "Batch [91/92]; Loss: 0.04883; Mean absolute error: 11.46875\n",
      "Train Loss: 0.05475; Train Metric: 18.26584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:33<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.16555; Validation Metric: 39.06986\n"
     ]
    }
   ],
   "source": [
    "num_epochs = config[\"training\"][\"num_epochs\"]\n",
    "model = LongformerForTokenClassification(\n",
    "    device=DEVICE, **config[\"model_config\"]\n",
    ").to(DEVICE)\n",
    "loss_fn = get_loss_fn(config[\"training\"][\"loss\"], DEVICE)\n",
    "optimizer_config = config[\"training\"][\"optimizer\"]\n",
    "scheduler_config = config[\"training\"][\"scheduler\"]\n",
    "metric_fn, is_better_metric_fn = get_metric(config[\"training\"][\"metric\"])\n",
    "num_epochs_before_finetune = config[\"training\"][\"num_epochs_before_finetune\"]\n",
    "\n",
    "best_model, df_history = training_loop(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer_config,\n",
    "    scheduler_config,\n",
    "    DEVICE,\n",
    "    metric_fn,\n",
    "    is_better_metric_fn,\n",
    "    num_epochs_before_finetune,\n",
    "    results_dir=results_dir,  # None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def make_predictions(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    results_dir,\n",
    "    label_column,\n",
    "    file_format=\"csv\",\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            ids = batch[\"id\"]\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "            corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "            _, logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=targets,\n",
    "            )\n",
    "\n",
    "            predictions, true_predictions = model.get_predictions_from_logits(\n",
    "                logits=logits,\n",
    "                labels=targets,\n",
    "                corresponding_word=corresponding_word\n",
    "            )\n",
    "\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            all_true.extend(true_predictions.tolist())\n",
    "            all_ids.extend(ids)\n",
    "\n",
    "    df_predictions = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": all_ids,\n",
    "            \"true\": all_true,\n",
    "            label_column: all_predictions,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if results_dir is not None:\n",
    "        if file_format == \"csv\":\n",
    "            df_predictions.to_csv(\n",
    "                os.path.join(results_dir, \"submission.csv\"),\n",
    "                index=False,\n",
    "            )\n",
    "        elif file_format == \"jsonl\":\n",
    "            df_predictions.to_json(\n",
    "                os.path.join(results_dir, \"submission.jsonl\"),\n",
    "                orient=\"records\",\n",
    "                lines=True,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown file format: {file_format}\")\n",
    "    else:\n",
    "        print(\"Missing results_dir, not saving predictions to file!\")\n",
    "\n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:23<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = make_predictions(\n",
    "    best_model,\n",
    "    test_dataloader,\n",
    "    DEVICE,\n",
    "    results_dir,\n",
    "    config[\"data\"][\"label_column\"],\n",
    "    file_format=\"csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation\n",
      "MAE: 39.06986\n",
      "--------------------\n",
      "Results on test\n",
      "MAE: 34.36832\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "!python ../scores_and_plots.py --results-dir \"../runs/29-12-2023_13:52:52-SubtaskC-longformer\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

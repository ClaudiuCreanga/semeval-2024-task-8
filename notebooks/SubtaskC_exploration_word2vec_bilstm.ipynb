{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmarchitan/Developer/ml_research/machine-generated_text_detection/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from lib.utils import get_device, get_current_date\n",
    "from lib.utils.constants import Subtask, Track, PreprocessTextLevel, DatasetType\n",
    "from lib.utils.models import sequential_fully_connected\n",
    "from lib.data.loading import load_train_dev_test_df\n",
    "from lib.data.tokenizer import get_tokenizer\n",
    "from lib.training.optimizer import get_optimizer, get_scheduler\n",
    "from lib.training.loss import get_loss_fn\n",
    "from lib.training.metric import get_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE_PATH = os.path.relpath(\"../config.json\")\n",
    "\n",
    "config = {}\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Track not specified in config for subtask: Subtask.SubtaskC\n",
      "Loading train data...\n",
      "Train/dev split... (df_train.shape: (3649, 3))\n",
      "Loading test data... ---> .././data/original_data/SubtaskC/SubtaskC_dev.jsonl\n",
      "df_train.shape: (2919, 3)\n",
      "df_dev.shape: (730, 3)\n",
      "df_test.shape: (505, 3)\n"
     ]
    }
   ],
   "source": [
    "task = None\n",
    "if \"task\" in config:\n",
    "    task = Subtask(config[\"task\"])\n",
    "else:\n",
    "    raise ValueError(\"Task not specified in config\")\n",
    "\n",
    "track = None\n",
    "if \"track\" in config:\n",
    "    track = Track(config[\"track\"])\n",
    "else:\n",
    "    print(f\"Warning: Track not specified in config for subtask: {task}\")\n",
    "\n",
    "dataset_type = DatasetType.TransformerTruncationDataset\n",
    "if \"dataset_type\" in config[\"data\"]:\n",
    "    dataset_type = DatasetType(config[\"data\"][\"dataset_type\"])\n",
    "\n",
    "dataset_type_settings = None\n",
    "if \"dataset_type_settings\" in config[\"data\"]:\n",
    "    dataset_type_settings = config[\"data\"][\"dataset_type_settings\"]\n",
    "\n",
    "df_train, df_dev, df_test = load_train_dev_test_df(\n",
    "    task=task,\n",
    "    track=track,\n",
    "    data_dir=f\"../{config['data']['data_dir']}\",\n",
    "    label_column=config[\"data\"][\"label_column\"],\n",
    "    test_size=config[\"data\"][\"test_size\"],\n",
    "    preprocess_text_level=PreprocessTextLevel(\n",
    "        config[\"data\"][\"preprocess_text_level\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"df_train.shape: {df_train.shape}\")\n",
    "print(f\"df_dev.shape: {df_dev.shape}\")\n",
    "print(f\"df_test.shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save results to: ../runs/30-12-2023_20:25:57-SubtaskC-bilstm_for_token_classification\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    results_dir = os.path.relpath(\"../runs/SubtaskC/\")\n",
    "else:\n",
    "    results_dir = os.path.relpath(\n",
    "        f\"../runs/{get_current_date()}-{task.value}-{config['model']}\"\n",
    "    )\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "print(f\"Will save results to: {results_dir}\")\n",
    "\n",
    "with open(results_dir + \"/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>4a33ddc4-b755-42f3-8526-f0b4f1b3626c</td>\n",
       "      <td>This paper is the first (I believe) to establi...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>f232cb20-24d5-439c-9634-791d2cf51873</td>\n",
       "      <td>This manuscript tries to tackle neural network...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>c001a50d-de63-49e8-acb1-4665391f9381</td>\n",
       "      <td>This paper proposes an extension of the MAC me...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>09299ba2-0870-4fdc-91f8-ceb29dddb958</td>\n",
       "      <td>The paper proposes two methods for what is cal...</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>fa7bc655-b107-4258-9c26-42b9bdb89e09</td>\n",
       "      <td>SUMMARY \\r\\nThis paper discusses how data from...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  \\\n",
       "2784  4a33ddc4-b755-42f3-8526-f0b4f1b3626c   \n",
       "2988  f232cb20-24d5-439c-9634-791d2cf51873   \n",
       "2718  c001a50d-de63-49e8-acb1-4665391f9381   \n",
       "2223  09299ba2-0870-4fdc-91f8-ceb29dddb958   \n",
       "1284  fa7bc655-b107-4258-9c26-42b9bdb89e09   \n",
       "\n",
       "                                                   text  label  \n",
       "2784  This paper is the first (I believe) to establi...     89  \n",
       "2988  This manuscript tries to tackle neural network...     55  \n",
       "2718  This paper proposes an extension of the MAC me...    150  \n",
       "2223  The paper proposes two methods for what is cal...    133  \n",
       "1284  SUMMARY \\r\\nThis paper discusses how data from...     43  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD2VEC_MODEL_NAME = \"word2vec-google-news-300\"\n",
    "# WORD2VEC_MODEL_NAME = \"glove-wiki-gigaword-300\"\n",
    "WORD2VEC_MODEL_NAME = \"fasttext-wiki-news-subwords-300\"  # ~ 50% (train), 60% (dev), 64% (test) word coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as gensim_api\n",
    "\n",
    "word2vec_model = gensim_api.load(WORD2VEC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many words from the dataset are in the word2vec model\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_words_in_word2vec_model(df, word2vec_model):\n",
    "    word_counts = Counter()\n",
    "    for text in df[\"text\"]:\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\r\", \" \")\n",
    "\n",
    "        words = [w for w in text.split(\" \") if w != \"\"]\n",
    "\n",
    "        word_counts.update(words)\n",
    "\n",
    "    word2vec_words = set(word2vec_model.index_to_key)\n",
    "    dataset_words = set(word_counts.keys())\n",
    "\n",
    "    print(f\"Number of words in the word2vec model: {len(word2vec_words)}\")\n",
    "    print(f\"Number of words in the dataset: {len(dataset_words)}\")\n",
    "\n",
    "    common_words = word2vec_words.intersection(dataset_words)\n",
    "    percentage = len(common_words) / len(dataset_words) * 100\n",
    "\n",
    "    print(\n",
    "        f\"Number of words in the dataset that are in the word2vec model: {len(common_words)} ({percentage:.2f}%)\"\n",
    "    )\n",
    "\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the word2vec model: 999999\n",
      "Number of words in the dataset: 22625\n",
      "Number of words in the dataset that are in the word2vec model: 11185 (49.44%)\n",
      "Number of words in the word2vec model: 999999\n",
      "Number of words in the dataset: 12553\n",
      "Number of words in the dataset that are in the word2vec model: 7447 (59.32%)\n",
      "Number of words in the word2vec model: 999999\n",
      "Number of words in the dataset: 7873\n",
      "Number of words in the dataset that are in the word2vec model: 5038 (63.99%)\n"
     ]
    }
   ],
   "source": [
    "_ = count_words_in_word2vec_model(df_train, word2vec_model)\n",
    "_ = count_words_in_word2vec_model(df_dev, word2vec_model)\n",
    "_ = count_words_in_word2vec_model(df_test, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "print(type(word2vec_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def split_text_into_words(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = text.replace(\"\\r\", \" \")\n",
    "\n",
    "    words = [w for w in text.split(\" \") if w != \"\"]\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    unknown_token = \"<UNK>\"\n",
    "    padding_token = \"<PAD>\"\n",
    "\n",
    "    unknown_token_idx = 0\n",
    "    padding_token_idx = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start_idx = 2\n",
    "        self.word2idx = {\n",
    "            Vocabulary.unknown_token: Vocabulary.unknown_token_idx,\n",
    "            Vocabulary.padding_token: Vocabulary.padding_token_idx,\n",
    "        }\n",
    "        self.idx2word = {\n",
    "            Vocabulary.unknown_token_idx: Vocabulary.unknown_token,\n",
    "            Vocabulary.padding_token_idx: Vocabulary.padding_token,\n",
    "        }\n",
    "\n",
    "    def build_vocabulary(self, df: pd.DataFrame):\n",
    "        idx = self.start_idx\n",
    "        for text in tqdm(df[\"text\"], desc=\"Building vocabulary\"):\n",
    "            words = split_text_into_words(text)\n",
    "\n",
    "            for word in words:\n",
    "                if word in self.word2idx:\n",
    "                    continue\n",
    "\n",
    "                # word is not in word2idx\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word\n",
    "\n",
    "                idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocabulary: 100%|██████████| 2919/2919 [00:00<00:00, 34085.70it/s]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Vocabulary()\n",
    "vocabulary.build_vocabulary(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 22627\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {len(vocabulary.word2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unknown_words(vocab, df):\n",
    "    all_words = set()\n",
    "    unknown_words = set()\n",
    "    for text in tqdm(df[\"text\"], desc=\"Counting unknown words\"):\n",
    "        words = split_text_into_words(text)\n",
    "\n",
    "        for word in words:\n",
    "            all_words.add(word)\n",
    "            if word not in vocab.word2idx:\n",
    "                unknown_words.add(word)\n",
    "\n",
    "    return all_words, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting unknown words: 100%|██████████| 730/730 [00:00<00:00, 23214.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown words in dev: 2206/12553 (17.57%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting unknown words: 100%|██████████| 505/505 [00:00<00:00, 33063.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown words in test: 2229/7873 (28.31%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_all_words, dev_unknown_words = get_unknown_words(vocabulary, df_dev)\n",
    "print(f\"Number of unknown words in dev: {len(dev_unknown_words)}/{len(dev_all_words)} ({len(dev_unknown_words) / len(dev_all_words) * 100:.2f}%)\")\n",
    "\n",
    "test_all_words, test_unknown_words = get_unknown_words(vocabulary, df_test)\n",
    "print(f\"Number of unknown words in test: {len(test_unknown_words)}/{len(test_all_words)} ({len(test_unknown_words) / len(test_all_words) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TokenClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ids: np.ndarray,\n",
    "        texts: np.ndarray,\n",
    "        targets: np.ndarray | None,\n",
    "        vocabulary: Vocabulary,\n",
    "        max_len: int,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ids = ids\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.vocab = vocabulary\n",
    "        self.max_len = max_len\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item_id = self.ids[index]\n",
    "        text = self.texts[index]\n",
    "        target = -1 if self.targets is None else self.targets[index]\n",
    "        targets_available = False if target == -1 else True\n",
    "\n",
    "        words = split_text_into_words(text)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Words: {words}\")\n",
    "            print(f\"Machine text start position: {target}\")\n",
    "            print()\n",
    "\n",
    "        targets = []\n",
    "        corresponding_word = []\n",
    "        tokens = []\n",
    "        input_ids = []\n",
    "        attention_mask = []\n",
    "\n",
    "        for idx, word in enumerate(words):\n",
    "            # word_encoded = self.tokenizer.tokenize(word)  # No [CLS] or [SEP]\n",
    "            # sub_words = len(word_encoded)\n",
    "\n",
    "            if targets_available:\n",
    "                is_machine_text = 1 if idx >= target else 0\n",
    "                # targets.extend([is_machine_text] * sub_words)\n",
    "                targets.append(is_machine_text)\n",
    "\n",
    "            corresponding_word.append(idx)\n",
    "            tokens.append(word)\n",
    "            input_ids.append(\n",
    "                self.vocab.word2idx.get(word, self.vocab.unknown_token_idx)\n",
    "            )\n",
    "            attention_mask.append(1)\n",
    "\n",
    "            if self.debug:\n",
    "                print(\n",
    "                    f\"word[{idx}]:\\n\"\n",
    "                    f\"{'':-<5}> tokens: {[word]}\\n\"\n",
    "                    f\"{'':-<5}> corresponding_word: {corresponding_word[-1]}\\n\"\n",
    "                    f\"{'':-<5}> input_ids: {input_ids[-1]}\\n\"\n",
    "                    f\"{'':-<5}> is_machine_text: {is_machine_text}\"\n",
    "                )\n",
    "\n",
    "        if self.debug:\n",
    "            print()\n",
    "\n",
    "            print(f\"corresponding_word: {corresponding_word}\")\n",
    "            print(f\"tokens: {tokens}\")\n",
    "            print(f\"input_ids: {input_ids}\")\n",
    "            print(f\"attention_mask: {attention_mask}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "            print(f\"Machine text start word: {words[targets.index(1)]}\")\n",
    "            print(f\"True machine text start word: {words[target]}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "        if len(input_ids) < self.max_len:\n",
    "            if targets_available:\n",
    "                targets = (\n",
    "                    targets\n",
    "                    + [-100] * (self.max_len - len(input_ids))\n",
    "                )\n",
    "\n",
    "            corresponding_word = (\n",
    "                # [-100]\n",
    "                corresponding_word\n",
    "                + [-100] * (self.max_len - len(input_ids))\n",
    "            )\n",
    "            tokens = (\n",
    "                # [self.tokenizer.bos_token]\n",
    "                tokens\n",
    "                # + [self.tokenizer.eos_token]\n",
    "                + [self.vocab.padding_token] * (self.max_len - len(tokens))\n",
    "            )\n",
    "            input_ids = (\n",
    "                # [self.tokenizer.bos_token_id]\n",
    "                input_ids\n",
    "                # + [self.tokenizer.eos_token_id]\n",
    "                + [self.vocab.padding_token_idx] * (self.max_len - len(input_ids))\n",
    "            )\n",
    "            attention_mask = (\n",
    "                # [1]\n",
    "                attention_mask\n",
    "                + [0] * (self.max_len - len(attention_mask))\n",
    "            )\n",
    "        else:\n",
    "            if targets_available:\n",
    "                targets = targets[: self.max_len]\n",
    "\n",
    "            corresponding_word = corresponding_word[: self.max_len]\n",
    "            # corresponding_word = (\n",
    "            #     [-100]\n",
    "            #     + corresponding_word[: self.max_len - 2]\n",
    "            #     + [-100]\n",
    "            # )\n",
    "            tokens = tokens[: self.max_len]\n",
    "            # tokens = (\n",
    "            #     [self.tokenizer.bos_token]\n",
    "            #     + tokens[: self.max_len - 2]\n",
    "            #     + [self.tokenizer.eos_token]\n",
    "            # )\n",
    "            input_ids = input_ids[: self.max_len]\n",
    "            # input_ids = (\n",
    "            #     [self.tokenizer.bos_token_id]\n",
    "            #     + input_ids[: self.max_len - 2]\n",
    "            #     + [self.tokenizer.eos_token_id]\n",
    "            # )\n",
    "            attention_mask = attention_mask[: self.max_len]\n",
    "            # attention_mask = (\n",
    "            #     [1]\n",
    "            #     + attention_mask[: self.max_len - 2]\n",
    "            #     + [1]\n",
    "            # )\n",
    "\n",
    "        encoded = {}\n",
    "        encoded[\"id\"] = item_id\n",
    "        encoded[\"text\"] = text\n",
    "        encoded[\"true_target\"] = torch.tensor(target)\n",
    "        encoded[\"corresponding_word\"] = torch.tensor(corresponding_word)\n",
    "        encoded[\"input_ids\"] = torch.tensor(input_ids)\n",
    "        encoded[\"attention_mask\"] = torch.tensor(attention_mask)\n",
    "        if targets_available:\n",
    "            encoded[\"target\"] = torch.tensor(targets)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Tokenized human position: {targets.index(1)}\")\n",
    "            print(f\"Original human position: {target}\")\n",
    "            print(f\"Full human text: {text}\\n\\n\")\n",
    "            print(f\"Human truncated text: {[w for w in text.split(' ')[:target] if w != '']}\\n\\n\")\n",
    "\n",
    "            encoded[\"partial_human_review\"] = \" \".join(\n",
    "                [w for w in text.split(' ')[:target] if w != '']\n",
    "            )\n",
    "\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# tokenizer = get_tokenizer(**config[\"tokenizer\"])\n",
    "\n",
    "train_dataset = TokenClassificationDataset(\n",
    "    ids=df_train[\"id\"].values,\n",
    "    texts=df_train[\"text\"].values,\n",
    "    targets=df_train[\"label\"].values,\n",
    "    vocabulary=vocabulary,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "dev_dataset = TokenClassificationDataset(\n",
    "    ids=df_dev[\"id\"].values,\n",
    "    texts=df_dev[\"text\"].values,\n",
    "    targets=df_dev[\"label\"].values,\n",
    "    vocabulary=vocabulary,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "test_dataset = TokenClassificationDataset(\n",
    "    ids=df_test[\"id\"].values,\n",
    "    texts=df_test[\"text\"].values,\n",
    "    targets=df_test[\"label\"].values,\n",
    "    vocabulary=vocabulary,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "dev_dataloader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paper'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.idx2word[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(train_dataloader):\n",
    "#     print(f\"Batch=[{i + 1}/{len(train_dataloader)}]\")\n",
    "#     print(f\"batch['input_ids'].shape: {batch['input_ids'].shape}\")\n",
    "#     print(f\"batch['attention_mask'].shape: {batch['attention_mask'].shape}\")\n",
    "#     print(f\"batch['target'].shape: {batch['target'].shape}\")\n",
    "#     print(f\"batch['target']: {batch['target']}\")\n",
    "#     print(f\"batch['corresponding_word']: {batch['corresponding_word']}\")\n",
    "#     break\n",
    "\n",
    "# for i, batch in enumerate(dev_dataloader):\n",
    "#     print(f\"Batch=[{i + 1}/{len(dev_dataloader)}]\")\n",
    "# #     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BiLSTM model for token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import LongformerModel\n",
    "\n",
    "\n",
    "class BiLSTMForTokenClassification(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        out_size,\n",
    "        device,\n",
    "        dropout_p=0.3,\n",
    "        n_layers=1,\n",
    "        hidden_dim=32,\n",
    "        fc=[],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_size = out_size\n",
    "        self.device = device\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            n_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.classifier = nn.Linear(2 * hidden_dim, out_size)\n",
    "        # self.classifier = sequential_fully_connected(\n",
    "        #     2 * hidden_dim, out_size, fc, dropout_p\n",
    "        # )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        embeddings = self.embedding(input_ids)\n",
    "        # print(f\"embeddings.shape: {embeddings.shape}\")\n",
    "\n",
    "        lengths = attention_mask.sum(dim=1)\n",
    "        # print(f\"lengths.shape: {lengths.shape}\")\n",
    "\n",
    "        packed_embeddings = nn.utils.rnn.pack_padded_sequence(\n",
    "            embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        # print(f\"packed_embeddings.data.shape: {packed_embeddings.data.shape}\")\n",
    "\n",
    "        packed_output, (_, _) = self.lstm(packed_embeddings)\n",
    "        # print(f\"packed_output.data.shape: {packed_output.data.shape}\")\n",
    "\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_output, batch_first=True, total_length=embeddings.shape[1],\n",
    "        )\n",
    "        # print(f\"output.shape: {output.shape}\")\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss().to(self.device)\n",
    "            loss = loss_fn(logits.view(-1, self.out_size), labels.view(-1))\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "    def freeze_transformer_layer(self):\n",
    "        pass\n",
    "\n",
    "    def unfreeze_transformer_layer(self):\n",
    "        pass\n",
    "\n",
    "    def get_predictions_from_logits(self, logits, labels=None, corresponding_word=None):\n",
    "        # batch_size = logits.shape[0]\n",
    "\n",
    "        # logits: (batch_size, max_seq_len, out_size)\n",
    "        # labels: (batch_size, max_seq_len)\n",
    "        # corresponding_word: (batch_size, max_seq_len)\n",
    "\n",
    "        # print(f\"logits.shape: {logits.shape}\")\n",
    "        # print(f\"logits: {logits}\")\n",
    "\n",
    "        # preds: (batch_size, max_seq_len)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # print(f\"preds.shape: {preds.shape}\")\n",
    "        # print(f\"preds: {preds}\")\n",
    "\n",
    "        if labels is not None:\n",
    "            # print(f\"labels.shape: {labels.shape}\")\n",
    "            # print(f\"labels: {labels}\")\n",
    "\n",
    "            # Keep only predictions where labels are not -100\n",
    "            # clean_preds = preds[labels != -100].reshape(batch_size, -1)\n",
    "            # clean_labels = labels[labels != -100].reshape(batch_size, -1)\n",
    "\n",
    "            # print(f\"clean_preds.shape: {clean_preds.shape}\")\n",
    "            # print(f\"clean_preds: {clean_preds}\")\n",
    "\n",
    "            # print(f\"clean_labels.shape: {clean_labels.shape}\")\n",
    "            # print(f\"clean_labels: {clean_labels}\")\n",
    "\n",
    "            # Get the index of the first machine text word\n",
    "            # predicted_positions = clean_preds.argmax(dim=-1)\n",
    "            # true_positions = clean_labels.argmax(dim=-1)\n",
    "\n",
    "            predicted_positions = []\n",
    "            true_positions = []\n",
    "            for p, l in zip(preds, labels):\n",
    "                mask = l != -100\n",
    "\n",
    "                clean_pred = p[mask]\n",
    "                clean_label = l[mask]\n",
    "\n",
    "                # print(f\"clean_pred.shape: {clean_pred.shape}\")\n",
    "                # print(f\"clean_pred: {clean_pred}\")\n",
    "                # print(f\"clean_label.shape: {clean_label.shape}\")\n",
    "                # print(f\"clean_label: {clean_label}\")\n",
    "\n",
    "                predicted_position = clean_pred.argmax(dim=-1)\n",
    "                true_position = clean_label.argmax(dim=-1)\n",
    "\n",
    "                # print(f\"predicted_position: {predicted_position}\")\n",
    "                # print(f\"true_position: {true_position}\")\n",
    "\n",
    "                predicted_positions.append(predicted_position.item())\n",
    "                true_positions.append(true_position.item())\n",
    "\n",
    "            # print(f\"predicted_positions.shape: {predicted_positions.shape}\")\n",
    "            # print(f\"predicted_positions: {predicted_positions}\")\n",
    "\n",
    "            # print(f\"true_positions.shape: {true_positions.shape}\")\n",
    "            # print(f\"true_positions: {true_positions}\")\n",
    "\n",
    "            # print(f\"predicted_positions type: {type(predicted_positions)}\")\n",
    "            # print(f\"true_positions type: {type(true_positions)}\")\n",
    "\n",
    "            return torch.Tensor(predicted_positions), torch.Tensor(true_positions)\n",
    "        elif corresponding_word is not None:\n",
    "            # print(f\"corresponding_word.shape: {corresponding_word.shape}\")\n",
    "            # print(f\"corresponding_word: {corresponding_word}\")\n",
    "\n",
    "            # Keep only predictions where corresponding_word are not -100\n",
    "            # clean_preds = preds[corresponding_word != -100].reshape(\n",
    "            #     batch_size, -1\n",
    "            # ).detach().cpu().numpy()\n",
    "            # clean_corresponding_word = corresponding_word[corresponding_word != -100].reshape(\n",
    "            #     batch_size, -1\n",
    "            # ).detach().cpu().numpy()\n",
    "\n",
    "            # print(f\"clean_preds.shape: {clean_preds.shape}\")\n",
    "            # print(f\"clean_preds: {clean_preds}\")\n",
    "\n",
    "            # print(f\"clean_corresponding_word.shape: {clean_corresponding_word.shape}\")\n",
    "            # print(f\"clean_corresponding_word: {clean_corresponding_word}\")\n",
    "\n",
    "            predicted_positions = []\n",
    "            for p, w in zip(preds, corresponding_word):\n",
    "                mask = w != -100\n",
    "\n",
    "                clean_pred = p[mask]\n",
    "                clean_corresponding_word = w[mask]\n",
    "\n",
    "                # print(f\"clean_pred.shape: {clean_pred.shape}\")\n",
    "                # print(f\"clean_pred: {clean_pred}\")\n",
    "                # print(f\"clean_corresponding_word.shape: {clean_corresponding_word.shape}\")\n",
    "                # print(f\"clean_corresponding_word: {clean_corresponding_word}\")\n",
    "\n",
    "                # Get the index of the first machine text word\n",
    "                index = torch.where(clean_pred == 1)[0]\n",
    "                value = index[0] if index.size else len(clean_pred) - 1\n",
    "                position = clean_corresponding_word[value]\n",
    "\n",
    "                # print(f\"index: {index}\")\n",
    "                # print(f\"value: {value}\")\n",
    "                # print(f\"position: {position}\")\n",
    "\n",
    "                predicted_positions.append(position.item())\n",
    "            #     # pred = pred.detach().cpu().numpy()\n",
    "\n",
    "            #     index = np.where(pred == 1)[0]\n",
    "            #     value = index[0] if index.size else len(pred) - 1\n",
    "            #     position = clean_corresponding_word[idx][value]\n",
    "\n",
    "            #     predicted_positions.append(position.item())\n",
    "\n",
    "            # print(f\"predicted_positions: {predicted_positions}\")\n",
    "\n",
    "            return predicted_positions, None\n",
    "        else:\n",
    "            raise ValueError(\"Either labels or corresponding_word must be provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    metric_fn,\n",
    "    print_freq=10,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        ids = batch[\"id\"]\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"target\"].to(device)\n",
    "        corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "        loss, logits = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=targets,\n",
    "        )\n",
    "\n",
    "        predictions, true_predictions = model.get_predictions_from_logits(\n",
    "            logits=logits,\n",
    "            labels=targets,\n",
    "            corresponding_word=corresponding_word\n",
    "        )\n",
    "\n",
    "        # print(f\"predictions: {predictions}\")\n",
    "        # print(f\"true_predictions: {true_predictions}\")\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        all_predictions.extend(predictions.tolist())\n",
    "        all_true.extend(true_predictions.tolist())\n",
    "        all_ids.extend(ids)\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(\n",
    "                f\"Batch [{i + 1}/{len(dataloader)}]; \"\n",
    "                f\"Loss: {loss.item():.5f}; \"\n",
    "                f\"Mean absolute error: {metric_fn(true_predictions, predictions):.5f}\"\n",
    "            )\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return np.mean(losses), (all_ids, all_true, all_predictions)\n",
    "\n",
    "\n",
    "def validation_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    metric_fn,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            ids = batch[\"id\"]\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "            corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "            loss, logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=targets,\n",
    "            )\n",
    "\n",
    "            predictions, true_predictions = model.get_predictions_from_logits(\n",
    "                logits=logits,\n",
    "                labels=targets,\n",
    "                corresponding_word=corresponding_word\n",
    "            )\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            all_true.extend(true_predictions.tolist())\n",
    "            all_ids.extend(ids)\n",
    "\n",
    "    return np.mean(losses), (all_ids, all_true, all_predictions)\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer_config,\n",
    "    scheduler_config,\n",
    "    device,\n",
    "    metric_fn,\n",
    "    is_better_metric_fn,\n",
    "    num_epochs_before_finetune,\n",
    "    results_dir,\n",
    "):\n",
    "    history = defaultdict(list)\n",
    "    best_metric = None\n",
    "    best_model_state = None\n",
    "\n",
    "    optimizer = get_optimizer(model, optimizer_config, finetune=False)\n",
    "    scheduler = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        if epoch <= num_epochs_before_finetune:\n",
    "            print(\"Freeze transformer\")\n",
    "        else:\n",
    "            print(\"Finetune transformer\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        if epoch == num_epochs_before_finetune + 1:\n",
    "            model.unfreeze_transformer_layer()\n",
    "            optimizer = get_optimizer(model, optimizer_config, finetune=True)\n",
    "            scheduler = get_scheduler(\n",
    "                optimizer,\n",
    "                num_training_steps=len(train_dataloader) * num_epochs,\n",
    "                **scheduler_config,\n",
    "            )\n",
    "\n",
    "        train_loss, (train_ids, train_true, train_predict) = train_epoch(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            device,\n",
    "            scheduler,\n",
    "            metric_fn,\n",
    "        )\n",
    "\n",
    "        train_metric = metric_fn(train_true, train_predict)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.5f}; Train Metric: {train_metric:.5f}\")\n",
    "\n",
    "        dev_loss, (dev_ids, dev_true, dev_predict) = validation_epoch(\n",
    "            model,\n",
    "            dev_dataloader,\n",
    "            loss_fn,\n",
    "            device,\n",
    "            metric_fn,\n",
    "        )\n",
    "\n",
    "        dev_metric = metric_fn(dev_true, dev_predict)\n",
    "\n",
    "        print(\n",
    "            f\"Validation Loss: {dev_loss:.5f}; \"\n",
    "            f\"Validation Metric: {dev_metric:.5f}\"\n",
    "        )\n",
    "\n",
    "        history[\"train_metric\"].append(train_metric)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"dev_metric\"].append(dev_metric)\n",
    "        history[\"dev_loss\"].append(dev_loss)\n",
    "\n",
    "        if best_metric is None or is_better_metric_fn(train_metric, best_metric):\n",
    "            best_metric = train_metric\n",
    "            best_model_state = model.state_dict()\n",
    "            \n",
    "            if results_dir is not None:\n",
    "                torch.save(\n",
    "                    best_model_state,\n",
    "                    os.path.join(results_dir, \"best_model.bin\"),\n",
    "                )\n",
    "\n",
    "                df_train_predictions = pd.DataFrame(\n",
    "                    {\n",
    "                        \"id\": train_ids,\n",
    "                        \"true\": train_true,\n",
    "                        \"predict\": train_predict,\n",
    "                    }\n",
    "                )\n",
    "                df_train_predictions.to_csv(\n",
    "                    os.path.join(results_dir, \"best_model_train_predict.csv\"),\n",
    "                    index=False\n",
    "                )\n",
    "\n",
    "                df_dev_predictions = pd.DataFrame(\n",
    "                    {\n",
    "                        \"id\": dev_ids,\n",
    "                        \"true\": dev_true,\n",
    "                        \"predict\": dev_predict,\n",
    "                    }\n",
    "                )\n",
    "                df_dev_predictions.to_csv(\n",
    "                    os.path.join(results_dir, \"best_model_dev_predict.csv\"),\n",
    "                    index=False\n",
    "                )\n",
    "\n",
    "    df_history = pd.DataFrame(history)\n",
    "    if results_dir is not None:\n",
    "        df_history.to_csv(os.path.join(results_dir, \"history.csv\"), index=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(results_dir, \"best_model.bin\")))\n",
    "    else:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model, df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"model_config\"][\"vocab_size\"] = len(vocabulary.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir + \"/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Freeze transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.15373; Mean absolute error: 59.81250\n",
      "Batch [11/183]; Loss: 0.16196; Mean absolute error: 71.25000\n",
      "Batch [21/183]; Loss: 0.15641; Mean absolute error: 88.68750\n",
      "Batch [31/183]; Loss: 0.14351; Mean absolute error: 77.31250\n",
      "Batch [41/183]; Loss: 0.13299; Mean absolute error: 76.37500\n",
      "Batch [51/183]; Loss: 0.10646; Mean absolute error: 55.68750\n",
      "Batch [61/183]; Loss: 0.10958; Mean absolute error: 58.25000\n",
      "Batch [71/183]; Loss: 0.14069; Mean absolute error: 88.68750\n",
      "Batch [81/183]; Loss: 0.09015; Mean absolute error: 52.50000\n",
      "Batch [91/183]; Loss: 0.21523; Mean absolute error: 125.93750\n",
      "Batch [101/183]; Loss: 0.07662; Mean absolute error: 55.50000\n",
      "Batch [111/183]; Loss: 0.07462; Mean absolute error: 44.56250\n",
      "Batch [121/183]; Loss: 0.06212; Mean absolute error: 40.12500\n",
      "Batch [131/183]; Loss: 0.07933; Mean absolute error: 63.81250\n",
      "Batch [141/183]; Loss: 0.09035; Mean absolute error: 58.25000\n",
      "Batch [151/183]; Loss: 0.07449; Mean absolute error: 42.37500\n",
      "Batch [161/183]; Loss: 0.06157; Mean absolute error: 39.75000\n",
      "Batch [171/183]; Loss: 0.03270; Mean absolute error: 28.62500\n",
      "Batch [181/183]; Loss: 0.06558; Mean absolute error: 44.81250\n",
      "Train Loss: 0.10374; Train Metric: 63.87873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:47<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.06681; Validation Metric: 44.52055\n",
      "Epoch 2/10\n",
      "Freeze transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.04602; Mean absolute error: 36.81250\n",
      "Batch [11/183]; Loss: 0.04383; Mean absolute error: 51.00000\n",
      "Batch [21/183]; Loss: 0.06834; Mean absolute error: 27.81250\n",
      "Batch [31/183]; Loss: 0.04662; Mean absolute error: 28.25000\n",
      "Batch [41/183]; Loss: 0.04322; Mean absolute error: 34.06250\n",
      "Batch [51/183]; Loss: 0.07083; Mean absolute error: 45.18750\n",
      "Batch [61/183]; Loss: 0.05911; Mean absolute error: 53.31250\n",
      "Batch [71/183]; Loss: 0.07893; Mean absolute error: 59.93750\n",
      "Batch [81/183]; Loss: 0.03519; Mean absolute error: 38.62500\n",
      "Batch [91/183]; Loss: 0.04235; Mean absolute error: 47.50000\n",
      "Batch [101/183]; Loss: 0.04889; Mean absolute error: 22.12500\n",
      "Batch [111/183]; Loss: 0.05399; Mean absolute error: 24.18750\n",
      "Batch [121/183]; Loss: 0.02676; Mean absolute error: 40.00000\n",
      "Batch [131/183]; Loss: 0.02838; Mean absolute error: 23.43750\n",
      "Batch [141/183]; Loss: 0.04928; Mean absolute error: 56.56250\n",
      "Batch [151/183]; Loss: 0.04070; Mean absolute error: 14.75000\n",
      "Batch [161/183]; Loss: 0.03658; Mean absolute error: 17.93750\n",
      "Batch [171/183]; Loss: 0.04780; Mean absolute error: 27.81250\n",
      "Batch [181/183]; Loss: 0.02698; Mean absolute error: 9.31250\n",
      "Train Loss: 0.05063; Train Metric: 31.95409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:43<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.05163; Validation Metric: 20.59452\n",
      "Epoch 3/10\n",
      "Freeze transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.04366; Mean absolute error: 19.12500\n",
      "Batch [11/183]; Loss: 0.05490; Mean absolute error: 18.37500\n",
      "Batch [21/183]; Loss: 0.03935; Mean absolute error: 20.68750\n",
      "Batch [31/183]; Loss: 0.02577; Mean absolute error: 12.87500\n",
      "Batch [41/183]; Loss: 0.05576; Mean absolute error: 20.62500\n",
      "Batch [51/183]; Loss: 0.02477; Mean absolute error: 10.62500\n",
      "Batch [61/183]; Loss: 0.03898; Mean absolute error: 25.37500\n",
      "Batch [71/183]; Loss: 0.03936; Mean absolute error: 25.62500\n",
      "Batch [81/183]; Loss: 0.04097; Mean absolute error: 14.75000\n",
      "Batch [91/183]; Loss: 0.03692; Mean absolute error: 20.50000\n",
      "Batch [101/183]; Loss: 0.02481; Mean absolute error: 6.68750\n",
      "Batch [111/183]; Loss: 0.04031; Mean absolute error: 35.50000\n",
      "Batch [121/183]; Loss: 0.02166; Mean absolute error: 12.37500\n",
      "Batch [131/183]; Loss: 0.04032; Mean absolute error: 15.31250\n",
      "Batch [141/183]; Loss: 0.03923; Mean absolute error: 23.81250\n",
      "Batch [151/183]; Loss: 0.04334; Mean absolute error: 18.81250\n",
      "Batch [161/183]; Loss: 0.03315; Mean absolute error: 24.00000\n",
      "Batch [171/183]; Loss: 0.03759; Mean absolute error: 14.12500\n",
      "Batch [181/183]; Loss: 0.01723; Mean absolute error: 6.31250\n",
      "Train Loss: 0.03549; Train Metric: 17.66667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:44<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04963; Validation Metric: 18.84384\n",
      "Epoch 4/10\n",
      "Freeze transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.01945; Mean absolute error: 6.31250\n",
      "Batch [11/183]; Loss: 0.06987; Mean absolute error: 24.50000\n",
      "Batch [21/183]; Loss: 0.02924; Mean absolute error: 11.56250\n",
      "Batch [31/183]; Loss: 0.02093; Mean absolute error: 18.25000\n",
      "Batch [41/183]; Loss: 0.05690; Mean absolute error: 19.31250\n",
      "Batch [51/183]; Loss: 0.01946; Mean absolute error: 12.50000\n",
      "Batch [61/183]; Loss: 0.01902; Mean absolute error: 7.81250\n",
      "Batch [71/183]; Loss: 0.03602; Mean absolute error: 23.00000\n",
      "Batch [81/183]; Loss: 0.02870; Mean absolute error: 20.50000\n",
      "Batch [91/183]; Loss: 0.03629; Mean absolute error: 12.25000\n",
      "Batch [101/183]; Loss: 0.03286; Mean absolute error: 14.56250\n",
      "Batch [111/183]; Loss: 0.02758; Mean absolute error: 9.31250\n",
      "Batch [121/183]; Loss: 0.03881; Mean absolute error: 35.25000\n",
      "Batch [131/183]; Loss: 0.02054; Mean absolute error: 9.75000\n",
      "Batch [141/183]; Loss: 0.01888; Mean absolute error: 12.93750\n",
      "Batch [151/183]; Loss: 0.03241; Mean absolute error: 12.43750\n",
      "Batch [161/183]; Loss: 0.11020; Mean absolute error: 38.68750\n",
      "Batch [171/183]; Loss: 0.02317; Mean absolute error: 10.68750\n",
      "Batch [181/183]; Loss: 0.01603; Mean absolute error: 7.43750\n",
      "Train Loss: 0.02989; Train Metric: 15.72251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:45<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04624; Validation Metric: 17.76712\n",
      "Epoch 5/10\n",
      "Freeze transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.02916; Mean absolute error: 13.75000\n",
      "Batch [11/183]; Loss: 0.03356; Mean absolute error: 31.43750\n",
      "Batch [21/183]; Loss: 0.01953; Mean absolute error: 15.43750\n",
      "Batch [31/183]; Loss: 0.01619; Mean absolute error: 6.87500\n",
      "Batch [41/183]; Loss: 0.02369; Mean absolute error: 8.62500\n",
      "Batch [51/183]; Loss: 0.02932; Mean absolute error: 19.93750\n",
      "Batch [61/183]; Loss: 0.04251; Mean absolute error: 27.31250\n",
      "Batch [71/183]; Loss: 0.01511; Mean absolute error: 7.62500\n",
      "Batch [81/183]; Loss: 0.02230; Mean absolute error: 13.37500\n",
      "Batch [91/183]; Loss: 0.01751; Mean absolute error: 11.37500\n",
      "Batch [101/183]; Loss: 0.01205; Mean absolute error: 8.87500\n",
      "Batch [111/183]; Loss: 0.01676; Mean absolute error: 5.50000\n",
      "Batch [121/183]; Loss: 0.02062; Mean absolute error: 10.62500\n",
      "Batch [131/183]; Loss: 0.02553; Mean absolute error: 17.68750\n",
      "Batch [141/183]; Loss: 0.01728; Mean absolute error: 19.62500\n",
      "Batch [151/183]; Loss: 0.03912; Mean absolute error: 23.50000\n",
      "Batch [161/183]; Loss: 0.01717; Mean absolute error: 9.00000\n",
      "Batch [171/183]; Loss: 0.01620; Mean absolute error: 9.93750\n",
      "Batch [181/183]; Loss: 0.03457; Mean absolute error: 32.12500\n",
      "Train Loss: 0.02558; Train Metric: 13.71737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:45<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04960; Validation Metric: 16.84658\n",
      "Epoch 6/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.02572; Mean absolute error: 8.37500\n",
      "Batch [11/183]; Loss: 0.02046; Mean absolute error: 7.75000\n",
      "Batch [21/183]; Loss: 0.01542; Mean absolute error: 5.00000\n",
      "Batch [31/183]; Loss: 0.02257; Mean absolute error: 16.37500\n",
      "Batch [41/183]; Loss: 0.02323; Mean absolute error: 8.87500\n",
      "Batch [51/183]; Loss: 0.02098; Mean absolute error: 9.43750\n",
      "Batch [61/183]; Loss: 0.02762; Mean absolute error: 13.87500\n",
      "Batch [71/183]; Loss: 0.01383; Mean absolute error: 23.87500\n",
      "Batch [81/183]; Loss: 0.01536; Mean absolute error: 8.50000\n",
      "Batch [91/183]; Loss: 0.01899; Mean absolute error: 7.68750\n",
      "Batch [101/183]; Loss: 0.02547; Mean absolute error: 11.50000\n",
      "Batch [111/183]; Loss: 0.01708; Mean absolute error: 8.00000\n",
      "Batch [121/183]; Loss: 0.01922; Mean absolute error: 7.56250\n",
      "Batch [131/183]; Loss: 0.02196; Mean absolute error: 8.06250\n",
      "Batch [141/183]; Loss: 0.03595; Mean absolute error: 9.18750\n",
      "Batch [151/183]; Loss: 0.01974; Mean absolute error: 10.87500\n",
      "Batch [161/183]; Loss: 0.01302; Mean absolute error: 5.43750\n",
      "Batch [171/183]; Loss: 0.02718; Mean absolute error: 33.37500\n",
      "Batch [181/183]; Loss: 0.02568; Mean absolute error: 8.75000\n",
      "Train Loss: 0.02088; Train Metric: 10.40048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04662; Validation Metric: 17.16986\n",
      "Epoch 7/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.01447; Mean absolute error: 7.50000\n",
      "Batch [11/183]; Loss: 0.01448; Mean absolute error: 6.37500\n",
      "Batch [21/183]; Loss: 0.02111; Mean absolute error: 8.18750\n",
      "Batch [31/183]; Loss: 0.01382; Mean absolute error: 5.56250\n",
      "Batch [41/183]; Loss: 0.01419; Mean absolute error: 5.37500\n",
      "Batch [51/183]; Loss: 0.01474; Mean absolute error: 8.06250\n",
      "Batch [61/183]; Loss: 0.01334; Mean absolute error: 5.25000\n",
      "Batch [71/183]; Loss: 0.01809; Mean absolute error: 6.12500\n",
      "Batch [81/183]; Loss: 0.02191; Mean absolute error: 12.06250\n",
      "Batch [91/183]; Loss: 0.01524; Mean absolute error: 7.62500\n",
      "Batch [101/183]; Loss: 0.01152; Mean absolute error: 5.00000\n",
      "Batch [111/183]; Loss: 0.08918; Mean absolute error: 11.06250\n",
      "Batch [121/183]; Loss: 0.01108; Mean absolute error: 5.50000\n",
      "Batch [131/183]; Loss: 0.01181; Mean absolute error: 5.12500\n",
      "Batch [141/183]; Loss: 0.01287; Mean absolute error: 5.87500\n",
      "Batch [151/183]; Loss: 0.02342; Mean absolute error: 14.12500\n",
      "Batch [161/183]; Loss: 0.03890; Mean absolute error: 11.18750\n",
      "Batch [171/183]; Loss: 0.01543; Mean absolute error: 10.25000\n",
      "Batch [181/183]; Loss: 0.01426; Mean absolute error: 10.31250\n",
      "Train Loss: 0.02000; Train Metric: 9.65947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:47<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04602; Validation Metric: 17.62877\n",
      "Epoch 8/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.01330; Mean absolute error: 7.37500\n",
      "Batch [11/183]; Loss: 0.01692; Mean absolute error: 11.81250\n",
      "Batch [21/183]; Loss: 0.01514; Mean absolute error: 8.31250\n",
      "Batch [31/183]; Loss: 0.02421; Mean absolute error: 11.18750\n",
      "Batch [41/183]; Loss: 0.01799; Mean absolute error: 7.06250\n",
      "Batch [51/183]; Loss: 0.02732; Mean absolute error: 8.75000\n",
      "Batch [61/183]; Loss: 0.01556; Mean absolute error: 8.81250\n",
      "Batch [71/183]; Loss: 0.01025; Mean absolute error: 3.93750\n",
      "Batch [81/183]; Loss: 0.01797; Mean absolute error: 15.31250\n",
      "Batch [91/183]; Loss: 0.01838; Mean absolute error: 8.68750\n",
      "Batch [101/183]; Loss: 0.01185; Mean absolute error: 7.12500\n",
      "Batch [111/183]; Loss: 0.01189; Mean absolute error: 3.87500\n",
      "Batch [121/183]; Loss: 0.01679; Mean absolute error: 6.75000\n",
      "Batch [131/183]; Loss: 0.01715; Mean absolute error: 7.43750\n",
      "Batch [141/183]; Loss: 0.01366; Mean absolute error: 8.25000\n",
      "Batch [151/183]; Loss: 0.01423; Mean absolute error: 7.37500\n",
      "Batch [161/183]; Loss: 0.02225; Mean absolute error: 11.87500\n",
      "Batch [171/183]; Loss: 0.02278; Mean absolute error: 17.00000\n",
      "Batch [181/183]; Loss: 0.01606; Mean absolute error: 10.50000\n",
      "Train Loss: 0.01952; Train Metric: 9.54539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04674; Validation Metric: 16.91096\n",
      "Epoch 9/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.02742; Mean absolute error: 8.06250\n",
      "Batch [11/183]; Loss: 0.01666; Mean absolute error: 6.12500\n",
      "Batch [21/183]; Loss: 0.01392; Mean absolute error: 7.12500\n",
      "Batch [31/183]; Loss: 0.01057; Mean absolute error: 4.12500\n",
      "Batch [41/183]; Loss: 0.01642; Mean absolute error: 6.43750\n",
      "Batch [51/183]; Loss: 0.01552; Mean absolute error: 9.43750\n",
      "Batch [61/183]; Loss: 0.01986; Mean absolute error: 9.50000\n",
      "Batch [71/183]; Loss: 0.01220; Mean absolute error: 5.18750\n",
      "Batch [81/183]; Loss: 0.01526; Mean absolute error: 8.68750\n",
      "Batch [91/183]; Loss: 0.01278; Mean absolute error: 14.62500\n",
      "Batch [101/183]; Loss: 0.01462; Mean absolute error: 7.00000\n",
      "Batch [111/183]; Loss: 0.01602; Mean absolute error: 9.87500\n",
      "Batch [121/183]; Loss: 0.01397; Mean absolute error: 4.81250\n",
      "Batch [131/183]; Loss: 0.01096; Mean absolute error: 10.93750\n",
      "Batch [141/183]; Loss: 0.01392; Mean absolute error: 5.93750\n",
      "Batch [151/183]; Loss: 0.02916; Mean absolute error: 9.68750\n",
      "Batch [161/183]; Loss: 0.01794; Mean absolute error: 7.18750\n",
      "Batch [171/183]; Loss: 0.02300; Mean absolute error: 9.31250\n",
      "Batch [181/183]; Loss: 0.01275; Mean absolute error: 6.75000\n",
      "Train Loss: 0.01901; Train Metric: 9.26447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04578; Validation Metric: 16.78493\n",
      "Epoch 10/10\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/183]; Loss: 0.02704; Mean absolute error: 24.31250\n",
      "Batch [11/183]; Loss: 0.01934; Mean absolute error: 8.31250\n",
      "Batch [21/183]; Loss: 0.01703; Mean absolute error: 14.31250\n",
      "Batch [31/183]; Loss: 0.01351; Mean absolute error: 6.06250\n",
      "Batch [41/183]; Loss: 0.01481; Mean absolute error: 9.18750\n",
      "Batch [51/183]; Loss: 0.01268; Mean absolute error: 6.31250\n",
      "Batch [61/183]; Loss: 0.02178; Mean absolute error: 7.31250\n",
      "Batch [71/183]; Loss: 0.01337; Mean absolute error: 6.43750\n",
      "Batch [81/183]; Loss: 0.01670; Mean absolute error: 5.50000\n",
      "Batch [91/183]; Loss: 0.01604; Mean absolute error: 12.25000\n",
      "Batch [101/183]; Loss: 0.01810; Mean absolute error: 7.00000\n",
      "Batch [111/183]; Loss: 0.01416; Mean absolute error: 18.93750\n",
      "Batch [121/183]; Loss: 0.01426; Mean absolute error: 9.75000\n",
      "Batch [131/183]; Loss: 0.01816; Mean absolute error: 5.62500\n",
      "Batch [141/183]; Loss: 0.02182; Mean absolute error: 6.62500\n",
      "Batch [151/183]; Loss: 0.01804; Mean absolute error: 5.75000\n",
      "Batch [161/183]; Loss: 0.01226; Mean absolute error: 6.43750\n",
      "Batch [171/183]; Loss: 0.01647; Mean absolute error: 6.43750\n",
      "Batch [181/183]; Loss: 0.02725; Mean absolute error: 10.75000\n",
      "Train Loss: 0.01855; Train Metric: 9.20761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:57<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04623; Validation Metric: 16.70274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = config[\"training\"][\"num_epochs\"]\n",
    "model = BiLSTMForTokenClassification(\n",
    "    device=DEVICE, **config[\"model_config\"]\n",
    ").to(DEVICE)\n",
    "loss_fn = get_loss_fn(config[\"training\"][\"loss\"], DEVICE)\n",
    "optimizer_config = config[\"training\"][\"optimizer\"]\n",
    "scheduler_config = config[\"training\"][\"scheduler\"]\n",
    "metric_fn, is_better_metric_fn = get_metric(config[\"training\"][\"metric\"])\n",
    "num_epochs_before_finetune = config[\"training\"][\"num_epochs_before_finetune\"]\n",
    "\n",
    "best_model, df_history = training_loop(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer_config,\n",
    "    scheduler_config,\n",
    "    DEVICE,\n",
    "    metric_fn,\n",
    "    is_better_metric_fn,\n",
    "    num_epochs_before_finetune,\n",
    "    results_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def make_predictions(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    results_dir,\n",
    "    label_column,\n",
    "    file_format=\"csv\",\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            ids = batch[\"id\"]\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "            corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "            _, logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=targets,\n",
    "            )\n",
    "\n",
    "            predictions, true_predictions = model.get_predictions_from_logits(\n",
    "                logits=logits,\n",
    "                labels=targets,\n",
    "                corresponding_word=corresponding_word\n",
    "            )\n",
    "\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            all_true.extend(true_predictions.tolist())\n",
    "            all_ids.extend(ids)\n",
    "\n",
    "    df_predictions = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": all_ids,\n",
    "            \"true\": all_true,\n",
    "            label_column: all_predictions,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if results_dir is not None:\n",
    "        if file_format == \"csv\":\n",
    "            df_predictions.to_csv(\n",
    "                os.path.join(results_dir, \"submission.csv\"),\n",
    "                index=False,\n",
    "            )\n",
    "        elif file_format == \"jsonl\":\n",
    "            df_predictions.to_json(\n",
    "                os.path.join(results_dir, \"submission.jsonl\"),\n",
    "                orient=\"records\",\n",
    "                lines=True,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown file format: {file_format}\")\n",
    "    else:\n",
    "        print(\"Missing results_dir, not saving predictions to file!\")\n",
    "\n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = make_predictions(\n",
    "    best_model,\n",
    "    test_dataloader,\n",
    "    DEVICE,\n",
    "    results_dir,\n",
    "    config[\"data\"][\"label_column\"],\n",
    "    file_format=\"csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation\n",
      "MAE: 16.70274\n",
      "--------------------\n",
      "Results on test\n",
      "MAE: 18.14851\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "!python ../scores_and_plots.py --results-dir \"../runs/30-12-2023_20:25:57-SubtaskC-bilstm_for_token_classification\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9bdf1e-89cf-4290-aeef-01e9329b764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizer, BertModel, BatchEncoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "422cb232-15c0-4ab1-916b-d5ac2706a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,  \"../\")\n",
    "\n",
    "import importlib\n",
    "from lib.utils import get_current_date\n",
    "from lib.utils.constants import Subtask, Track, PreprocessTextLevel, PoolingStrategy, DatasetType\n",
    "from lib.utils.models import sequential_fully_connected\n",
    "from lib.data.loading import load_train_dev_test_df, build_data_loader\n",
    "from lib.data.tokenizer import get_tokenizer\n",
    "from lib.models import get_model\n",
    "from lib.training.loss import get_loss_fn\n",
    "from lib.training.metric import get_metric\n",
    "from lib.training.loops import training_loop, make_predictions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7457adb8-9350-4200-9783-0378a553a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE = os.path.relpath(\"../config.json\")\n",
    "\n",
    "CONFIG = {}\n",
    "with open(CONFIG_FILE) as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414be752-b14b-4bf7-8018-1f6fd980dcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'SubtaskA',\n",
       " 'track': 'monolingual',\n",
       " 'submission_format': 'csv',\n",
       " 'model': 'bert',\n",
       " 'tokenizer': {'model_name': 'bert', 'pretrained_name': 'bert-base-uncased'},\n",
       " 'data': {'dataset_type': 'transformer_truncation_dataset',\n",
       "  'dataset_type_settings': {'truncation_strategy': 'head_only'},\n",
       "  'data_dir': './data/original_data',\n",
       "  'label_column': 'label',\n",
       "  'max_len': 128,\n",
       "  'batch_size': 8,\n",
       "  'test_size': 0.2,\n",
       "  'preprocess_text_level': 0},\n",
       " 'model_config': {'pretrained_model_name': 'bert-base-uncased',\n",
       "  'out_size': 1,\n",
       "  'dropout_p': 0.5,\n",
       "  'fc': [128],\n",
       "  'out_activation': 'sigmoid'},\n",
       " 'training': {'num_epochs': 3,\n",
       "  'num_epochs_before_finetune': 2,\n",
       "  'optimizer': {'AdamW': {'freeze_lr': 0.001, 'finetune_lr': 2e-05}},\n",
       "  'scheduler': {'num_warmup_steps': 0},\n",
       "  'loss': 'bce',\n",
       "  'metric': 'accuracy'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b96d09-60b7-4168-b42a-f0df2df24efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Train/dev split... (df_train.shape: (119757, 5))\n",
      "Loading test data...\n",
      "df_train.shape: (95805, 5)\n",
      "df_dev.shape: (23952, 5)\n",
      "df_test.shape: (5000, 5)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_dev, df_test = load_train_dev_test_df(\n",
    "    task=Subtask(CONFIG[\"task\"]),\n",
    "    track=Track(CONFIG[\"track\"]),\n",
    "    data_dir=\"../data/original_data\",\n",
    "    label_column=CONFIG[\"data\"][\"label_column\"],\n",
    "    test_size=CONFIG[\"data\"][\"test_size\"],\n",
    "    preprocess_text_level=PreprocessTextLevel(\n",
    "        CONFIG[\"data\"][\"preprocess_text_level\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"df_train.shape: {df_train.shape}\")\n",
    "print(f\"df_dev.shape: {df_dev.shape}\")\n",
    "print(f\"df_test.shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb189fae-2346-4a59-9305-81841ae267fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 57.9kB/s]\n",
      "vocab.txt: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 1.51MB/s]\n",
      "tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 2.94MB/s]\n",
      "config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 1.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = CONFIG[\"data\"][\"max_len\"]\n",
    "tokenizer = get_tokenizer(**CONFIG[\"tokenizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de31ff4-be9a-4d98-acfe-c53d32539ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819d111e-4fd1-4ecb-a329-2342d3a699d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean cuda memroy\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbb46e75-dfb6-48b2-b843-8b35268578c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = build_data_loader(\n",
    "    df_train[:10],\n",
    "    tokenizer,\n",
    "    max_len=CONFIG[\"data\"][\"max_len\"],\n",
    "    batch_size=CONFIG[\"data\"][\"batch_size\"],\n",
    "    label_column=CONFIG[\"data\"][\"label_column\"],\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74d1a6fb-29ce-4329-b416-57e368c112e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained(\n",
    "    CONFIG[\"model_config\"][\"pretrained_model_name\"],\n",
    "    return_dict=False,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "bert_num_layers = len(bert.encoder.layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2327e078-83c4-4748-b44d-10bca620177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for p in bert.named_parameters():\n",
    "    print(p[0])\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ba1b6e6-4ee9-4fee-b272-d25be254bcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de26c22-645c-4cf7-a5e6-5935f04330ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTWithLayerSelection(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model_name: str,\n",
    "        out_size: int = 1,\n",
    "        dropout_p: float = 0.5,\n",
    "        selected_layers: [int] = [-1],\n",
    "        fc: [int] = [],\n",
    "        out_activation: str | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.selected_layers = selected_layers\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            pretrained_model_name, return_dict=False, output_hidden_states=True\n",
    "        )\n",
    "        # self.drop_bert = nn.Dropout(dropout_p)\n",
    "\n",
    "        input_size = len(selected_layers) * self.bert.config.hidden_size\n",
    "        self.out = sequential_fully_connected(input_size, out_size, fc, dropout_p)\n",
    "\n",
    "        self.out_activation = None\n",
    "        if out_activation == \"sigmoid\":\n",
    "            self.out_activation = nn.Sigmoid()\n",
    "\n",
    "        self.freeze_transformer_layer()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_outputs = self.bert(input_ids, attention_mask)\n",
    "        hidden_states = bert_outputs[2]\n",
    "        bert_cls_features = torch.cat(\n",
    "            [hidden_states[i][:, 0, :] for i in self.selected_layers],\n",
    "            dim=1,\n",
    "        )\n",
    "        # output = self.drop_bert(pooled_output)\n",
    "        output = self.out(bert_cls_features)\n",
    "\n",
    "        if self.out_activation is not None:\n",
    "            output = self.out_activation(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def freeze_transformer_layer(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_transformer_layer(self):\n",
    "        # BERT used only for feature extraction\n",
    "        pass\n",
    "\n",
    "    def get_predictions_from_outputs(self, outputs):\n",
    "        if self.out_activation is None:\n",
    "            return outputs.flatten().tolist()\n",
    "        else:\n",
    "            return torch.round(outputs).flatten().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98a3e615-7995-4110-935c-ce261bd7d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_layers_to_use = [-1, -2, -3, -4]\n",
    "CONFIG[\"model_config\"][\"selected_layers\"] = bert_layers_to_use\n",
    "bert_with_layer_selection = BERTWithLayerSelection(**CONFIG[\"model_config\"]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26bdd75a-f403-49c3-b635-7cd57d540b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "true = [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
      "predictions = [1.0, 0.0]\n",
      "true = [0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Bert with layer selection\n",
    "\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    ids = batch[\"id\"]\n",
    "    input_ids = batch[\"input_ids\"]  # .to(device)\n",
    "    attention_mask = batch[\"attention_mask\"]  # .to(device)\n",
    "    targets = batch[\"target\"].to(DEVICE)\n",
    "\n",
    "    outputs = bert_with_layer_selection(\n",
    "        input_ids=input_ids, attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    predictions = bert_with_layer_selection.get_predictions_from_outputs(outputs)\n",
    "    true = targets.flatten().tolist()\n",
    "\n",
    "    print(f\"predictions = {predictions}\")\n",
    "    print(f\"true = {true}\")\n",
    "\n",
    "    # expected_input_size = len(bert_layers_to_use) * bert.config.hidden_size\n",
    "    # print(f\"expected_input_size: {expected_input_size}\")\n",
    "\n",
    "    # embs = bert(input_ids, attention_mask)\n",
    "    # print(f\"embs[0].shape: {embs[0].shape}\")\n",
    "    # print(f\"embs[1].shape: {embs[1].shape}\")\n",
    "\n",
    "    # hidden_states = embs[2]\n",
    "    # selected_layers = [hidden_states[i] for i in bert_layers_to_use]\n",
    "\n",
    "    # # selected_layers = torch.cat(selected_layers, dim=2)\n",
    "    # # print(f\"selected_layers.shape: {selected_layers.shape}\")\n",
    "\n",
    "    # # mean_layer = torch.mean(selected_layers, dim=1)\n",
    "    # # print(f\"mean_layer.shape: {mean_layer.shape}\")\n",
    "\n",
    "    # cls_features = [layer[:, 0, :] for layer in selected_layers]\n",
    "    # cls_features = torch.cat(cls_features, dim=1)\n",
    "    # print(f\"cls_features.shape: {cls_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "226878bb-79bc-42f2-a66c-99ba93193163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Layer selection: 1-1_layers #####\n",
      "\n",
      "Will save results to: ../runs/15-12-2023_15:57:01-SubtaskA-monolingual-bert_1-1_layers\n",
      "\n",
      "da\n",
      "Starting training loop...\n",
      "2\n",
      "1\n",
      "Epoch 1/3\n",
      "Freeze transformeer\n",
      "--------------------\n",
      "dap\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "No such selected layers merge strategy: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m num_epochs_before_finetune \u001b[38;5;241m=\u001b[39m CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs_before_finetune\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdev_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_better_metric_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs_before_finetune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m make_predictions(\n\u001b[1;32m     88\u001b[0m     best_model,\n\u001b[1;32m     89\u001b[0m     test_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     file_format\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmission_format\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     94\u001b[0m )\n",
      "File \u001b[0;32m~/projects/machine-generated_text_detection/notebooks/../lib/training/loops.py:309\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, num_epochs, train_loader, dev_loader, loss_fn, optimizer_config, scheduler_config, device, metric_fn, is_better_metric_fn, results_dir, num_epochs_before_finetune, swa_config, validation_freq, fabric)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 309\u001b[0m     train_loss, (train_ids, train_true, train_predict) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mswa_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswa_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mswa_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswa_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mswa_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mswa_start\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfabric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfabric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    323\u001b[0m     elapsed_time_float, elapsed_time_str \u001b[38;5;241m=\u001b[39m elapsed_time(start_time, end_time)\n",
      "File \u001b[0;32m~/projects/machine-generated_text_detection/notebooks/../lib/training/loops.py:55\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, metric_fn, swa_model, swa_scheduler, swa_step, fabric, print_freq)\u001b[0m\n\u001b[1;32m     52\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_predictions_from_outputs(outputs)\n\u001b[1;32m     58\u001b[0m true \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda/envs/ml10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/ml10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/machine-generated_text_detection/notebooks/../lib/models/bert/bert.py:142\u001b[0m, in \u001b[0;36mBERT.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    135\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\n\u001b[1;32m    136\u001b[0m         torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m    137\u001b[0m             hidden_states[i][:, \u001b[38;5;241m0\u001b[39m, :] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_layers\n\u001b[1;32m    138\u001b[0m         ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    139\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    140\u001b[0m     )\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such selected layers merge strategy: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_layers_merge_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_layers_dropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_layers_dropout(output)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: No such selected layers merge strategy: None"
     ]
    }
   ],
   "source": [
    "selected_layers_options = {\n",
    "    \"1-1_layers\": [1],\n",
    "    \"1-2_layers\": [1, 2],\n",
    "    \"1-3_layers\": [1, 2, 3],\n",
    "    # \"1-4_layers\": [1, 2, 3, 4],\n",
    "    # \"1-5_layers\": [1, 2, 3, 4, 5],\n",
    "    # \"1-6_layers\": [1, 2, 3, 4, 5, 6],\n",
    "    # \"1-7_layers\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    # \"1-8_layers\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    # \"1-9_layers\": [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    # \"1-10_layers\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    # \"1-11_layers\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    # \"1-12_layers\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    # \"first_4_layers\": [1, 2, 3, 4],\n",
    "    # \"last_4_layers\": [-1, -2, -3, -4],\n",
    "}\n",
    "\n",
    "for selection_name, selected_layers in selected_layers_options.items():\n",
    "    print(f\"##### Layer selection: {selection_name} #####\\n\")\n",
    "\n",
    "    CONFIG[\"model_config\"][\"selected_layers\"] = selected_layers\n",
    "\n",
    "    if CONFIG[\"track\"] is None:\n",
    "        results_path = (\n",
    "            f\"../runs/{get_current_date()}-{CONFIG['task']}-{CONFIG['model']}_{selection_name}\"\n",
    "        )\n",
    "    else:\n",
    "        results_path = (\n",
    "            f\"../runs/{get_current_date()}-\"\n",
    "            f\"{CONFIG['task']}-{CONFIG['track']}-{CONFIG['model']}_{selection_name}\"\n",
    "        )\n",
    "\n",
    "    print(f\"Will save results to: {results_path}\\n\")\n",
    "    os.mkdir(results_path)\n",
    "\n",
    "    with open(results_path + \"/config.json\", \"w\") as f:\n",
    "        json.dump(CONFIG, f, indent=4)\n",
    "\n",
    "    train_dataloader = build_data_loader(\n",
    "        df_train[:100],\n",
    "        tokenizer,\n",
    "        max_len=CONFIG[\"data\"][\"max_len\"],\n",
    "        batch_size=CONFIG[\"data\"][\"batch_size\"],\n",
    "        label_column=CONFIG[\"data\"][\"label_column\"],\n",
    "        shuffle=True,\n",
    "    )\n",
    "    dev_dataloader = build_data_loader(\n",
    "        df_dev[:100],\n",
    "        tokenizer,\n",
    "        max_len=CONFIG[\"data\"][\"max_len\"],\n",
    "        batch_size=CONFIG[\"data\"][\"batch_size\"],\n",
    "        label_column=CONFIG[\"data\"][\"label_column\"],\n",
    "    )\n",
    "    test_dataloader = build_data_loader(\n",
    "        df_test[:100],\n",
    "        tokenizer,\n",
    "        max_len=CONFIG[\"data\"][\"max_len\"],\n",
    "        batch_size=CONFIG[\"data\"][\"batch_size\"],\n",
    "        label_column=CONFIG[\"data\"][\"label_column\"],\n",
    "        has_targets=False if CONFIG[\"data\"][\"test_size\"] is None else True,\n",
    "    )\n",
    "\n",
    "    num_epochs = CONFIG[\"training\"][\"num_epochs\"]\n",
    "    model = get_model(CONFIG[\"model\"], CONFIG[\"model_config\"]).to(DEVICE)\n",
    "    loss_fn = get_loss_fn(CONFIG[\"training\"][\"loss\"], DEVICE)\n",
    "    optimizer_config = CONFIG[\"training\"][\"optimizer\"]\n",
    "    scheduler_config = CONFIG[\"training\"][\"scheduler\"]\n",
    "    metric_fn, is_better_metric_fn = get_metric(CONFIG[\"training\"][\"metric\"])\n",
    "    num_epochs_before_finetune = CONFIG[\"training\"][\"num_epochs_before_finetune\"]\n",
    "    print(\"da\")\n",
    "    best_model = training_loop(\n",
    "        model,\n",
    "        num_epochs,\n",
    "        train_dataloader,\n",
    "        dev_dataloader,\n",
    "        loss_fn,\n",
    "        optimizer_config,\n",
    "        scheduler_config,\n",
    "        DEVICE,\n",
    "        metric_fn,\n",
    "        is_better_metric_fn,\n",
    "        results_path,\n",
    "        num_epochs_before_finetune,\n",
    "    )\n",
    "    print(\"da\")\n",
    "\n",
    "    make_predictions(\n",
    "        best_model,\n",
    "        test_dataloader,\n",
    "        DEVICE,\n",
    "        results_path,\n",
    "        label_column=CONFIG[\"data\"][\"label_column\"],\n",
    "        file_format=CONFIG[\"submission_format\"],\n",
    "    )\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7a908c7-547a-48e1-a3b0-bd7f08ba43c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'SubtaskA',\n",
       " 'track': 'monolingual',\n",
       " 'submission_format': 'csv',\n",
       " 'model': 'bert',\n",
       " 'tokenizer': {'model_name': 'bert', 'pretrained_name': 'bert-base-uncased'},\n",
       " 'data': {'dataset_type': 'transformer_truncation_dataset',\n",
       "  'dataset_type_settings': {'truncation_strategy': 'head_only'},\n",
       "  'data_dir': './data/original_data',\n",
       "  'label_column': 'label',\n",
       "  'max_len': 128,\n",
       "  'batch_size': 8,\n",
       "  'test_size': 0.2,\n",
       "  'preprocess_text_level': 0},\n",
       " 'model_config': {'pretrained_model_name': 'bert-base-uncased',\n",
       "  'out_size': 1,\n",
       "  'dropout_p': 0.5,\n",
       "  'fc': [128],\n",
       "  'out_activation': 'sigmoid',\n",
       "  'selected_layers': [1]},\n",
       " 'training': {'num_epochs': 3,\n",
       "  'num_epochs_before_finetune': 2,\n",
       "  'optimizer': {'AdamW': {'freeze_lr': 0.001, 'finetune_lr': 2e-05}},\n",
       "  'scheduler': {'num_warmup_steps': 0},\n",
       "  'loss': 'bce',\n",
       "  'metric': 'accuracy'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0d18fda-ec54-477e-a12c-f8721501ebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs_before_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127aacda-7d5d-41ab-829b-9ac96c556703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

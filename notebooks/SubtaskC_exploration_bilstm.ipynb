{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from lib.utils import get_device, get_current_date\n",
    "from lib.utils.constants import Subtask, Track, PreprocessTextLevel, DatasetType\n",
    "from lib.utils.models import sequential_fully_connected\n",
    "from lib.data.loading import load_train_dev_test_df\n",
    "from lib.data.tokenizer import get_tokenizer\n",
    "from lib.training.optimizer import get_optimizer, get_scheduler\n",
    "from lib.training.loss import get_loss_fn\n",
    "from lib.training.metric import get_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE_PATH = os.path.relpath(\"../config.json\")\n",
    "\n",
    "config = {}\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Track not specified in config for subtask: Subtask.SubtaskC\n",
      "Loading train data...\n",
      "Train/dev split... (df_train.shape: (3649, 3))\n",
      "Loading test data....././data/original_data/SubtaskC/SubtaskC_dev.jsonl\n",
      "df_train.shape: (2919, 3)\n",
      "df_dev.shape: (730, 3)\n",
      "df_test.shape: (505, 3)\n"
     ]
    }
   ],
   "source": [
    "task = None\n",
    "if \"task\" in config:\n",
    "    task = Subtask(config[\"task\"])\n",
    "else:\n",
    "    raise ValueError(\"Task not specified in config\")\n",
    "\n",
    "track = None\n",
    "if \"track\" in config:\n",
    "    track = Track(config[\"track\"])\n",
    "else:\n",
    "    print(f\"Warning: Track not specified in config for subtask: {task}\")\n",
    "\n",
    "dataset_type = DatasetType.TransformerTruncationDataset\n",
    "if \"dataset_type\" in config[\"data\"]:\n",
    "    dataset_type = DatasetType(config[\"data\"][\"dataset_type\"])\n",
    "\n",
    "dataset_type_settings = None\n",
    "if \"dataset_type_settings\" in config[\"data\"]:\n",
    "    dataset_type_settings = config[\"data\"][\"dataset_type_settings\"]\n",
    "\n",
    "df_train, df_dev, df_test = load_train_dev_test_df(\n",
    "    task=task,\n",
    "    track=track,\n",
    "    data_dir=f\"../{config['data']['data_dir']}\",\n",
    "    label_column=config[\"data\"][\"label_column\"],\n",
    "    test_size=config[\"data\"][\"test_size\"],\n",
    "    preprocess_text_level=PreprocessTextLevel(\n",
    "        config[\"data\"][\"preprocess_text_level\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"df_train.shape: {df_train.shape}\")\n",
    "print(f\"df_dev.shape: {df_dev.shape}\")\n",
    "print(f\"df_test.shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save results to: ../runs/29-12-2023_13:41:34-SubtaskC-longformer_bilstm\n"
     ]
    }
   ],
   "source": [
    "results_dir = os.path.relpath(\n",
    "    f\"../runs/{get_current_date()}-{task.value}-{config['model']}\"\n",
    ")\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "print(f\"Will save results to: {results_dir}\")\n",
    "\n",
    "with open(results_dir + \"/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "class TokenClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ids: np.ndarray,\n",
    "        texts: np.ndarray,\n",
    "        targets: np.ndarray | None,\n",
    "        tokenizer: PreTrainedTokenizer | None,\n",
    "        max_len: int,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if tokenizer is None:\n",
    "            raise ValueError(\"Tokenizer cannot be None\")\n",
    "\n",
    "        self.ids = ids\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item_id = self.ids[index]\n",
    "        text = self.texts[index]\n",
    "        target = -1 if self.targets is None else self.targets[index]\n",
    "        targets_available = False if target == -1 else True\n",
    "\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\r\", \" \")\n",
    "\n",
    "        words = [w for w in text.split(\" \") if w != \"\"]\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Words: {words}\")\n",
    "            print(f\"Machine text start position: {target}\")\n",
    "            print()\n",
    "\n",
    "        targets = []\n",
    "        corresponding_word = []\n",
    "        tokens = []\n",
    "        input_ids = []\n",
    "        attention_mask = []\n",
    "\n",
    "        for idx, word in enumerate(words):\n",
    "            word_encoded = self.tokenizer.tokenize(word)  # No [CLS] or [SEP]\n",
    "            sub_words = len(word_encoded)\n",
    "\n",
    "            if targets_available:\n",
    "                is_machine_text = 1 if idx >= target else 0\n",
    "                targets.extend([is_machine_text] * sub_words)\n",
    "\n",
    "            corresponding_word.extend([idx] * sub_words)\n",
    "            tokens.extend(word_encoded)\n",
    "            input_ids.extend(self.tokenizer.convert_tokens_to_ids(word_encoded))\n",
    "            attention_mask.extend([1] * sub_words)\n",
    "\n",
    "            if self.debug:\n",
    "                print(\n",
    "                    f\"word[{idx}]:\\n\"\n",
    "                    f\"{'':-<5}> tokens: {word_encoded} (no. of subwords: {sub_words})\\n\"\n",
    "                    f\"{'':-<5}> corresponding_word: {corresponding_word[-sub_words:]}\\n\"\n",
    "                    f\"{'':-<5}> input_ids: {input_ids[-sub_words:]}\\n\"\n",
    "                    f\"{'':-<5}> is_machine_text: {is_machine_text}\"\n",
    "                )\n",
    "\n",
    "        if self.debug:\n",
    "            print()\n",
    "\n",
    "            print(f\"corresponding_word: {corresponding_word}\")\n",
    "            print(f\"tokens: {tokens}\")\n",
    "            print(f\"input_ids: {input_ids}\")\n",
    "            print(f\"attention_mask: {attention_mask}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "            print(f\"Machine text start word: {words[corresponding_word[targets.index(1)]]}\")\n",
    "            print(f\"True machine text start word: {words[target]}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "        if len(input_ids) < self.max_len - 2:\n",
    "            if targets_available:\n",
    "                targets = (\n",
    "                    [-100]\n",
    "                    + targets\n",
    "                    + [-100] * (self.max_len - len(input_ids) - 1)\n",
    "                )\n",
    "\n",
    "            corresponding_word = (\n",
    "                [-100]\n",
    "                + corresponding_word\n",
    "                + [-100] * (self.max_len - len(input_ids) - 1)\n",
    "            )\n",
    "            tokens = (\n",
    "                [self.tokenizer.bos_token]\n",
    "                + tokens\n",
    "                + [self.tokenizer.eos_token]\n",
    "                + [self.tokenizer.pad_token] * (self.max_len - len(tokens) - 2)\n",
    "            )\n",
    "            input_ids = (\n",
    "                [self.tokenizer.bos_token_id]\n",
    "                + input_ids\n",
    "                + [self.tokenizer.eos_token_id]\n",
    "                + [self.tokenizer.pad_token_id] * (self.max_len - len(input_ids) - 2)\n",
    "            )\n",
    "            attention_mask = (\n",
    "                [1]\n",
    "                + attention_mask\n",
    "                + [1]\n",
    "                + [0] * (self.max_len - len(attention_mask) - 2)\n",
    "            )\n",
    "        else:\n",
    "            if targets_available:\n",
    "                targets = [-100] + targets[: self.max_len - 2] + [-100]\n",
    "\n",
    "            corresponding_word = (\n",
    "                [-100]\n",
    "                + corresponding_word[: self.max_len - 2]\n",
    "                + [-100]\n",
    "            )\n",
    "            tokens = (\n",
    "                [self.tokenizer.bos_token]\n",
    "                + tokens[: self.max_len - 2]\n",
    "                + [self.tokenizer.eos_token]\n",
    "            )\n",
    "            input_ids = (\n",
    "                [self.tokenizer.bos_token_id]\n",
    "                + input_ids[: self.max_len - 2]\n",
    "                + [self.tokenizer.eos_token_id]\n",
    "            )\n",
    "            attention_mask = (\n",
    "                [1]\n",
    "                + attention_mask[: self.max_len - 2]\n",
    "                + [1]\n",
    "            )\n",
    "\n",
    "        encoded = {}\n",
    "        encoded[\"id\"] = item_id\n",
    "        encoded[\"text\"] = text\n",
    "        encoded[\"true_target\"] = torch.tensor(target)\n",
    "        encoded[\"corresponding_word\"] = torch.tensor(corresponding_word)\n",
    "        encoded[\"input_ids\"] = torch.tensor(input_ids)\n",
    "        encoded[\"attention_mask\"] = torch.tensor(attention_mask)\n",
    "        if targets_available:\n",
    "            encoded[\"target\"] = torch.tensor(targets)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Tokenized human position: {targets.index(1)}\")\n",
    "            print(f\"Original human position: {target}\")\n",
    "            print(f\"Full human text: {text}\\n\\n\")\n",
    "            print(f\"Human truncated text: {[w for w in text.split(' ')[:target] if w != '']}\\n\\n\")\n",
    "\n",
    "            encoded[\"partial_human_review\"] = \" \".join(\n",
    "                [w for w in text.split(' ')[:target] if w != '']\n",
    "            )\n",
    "\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = get_tokenizer(**config[\"tokenizer\"])\n",
    "\n",
    "train_dataset = TokenClassificationDataset(\n",
    "    ids=df_train[\"id\"].values,\n",
    "    texts=df_train[\"text\"].values,\n",
    "    targets=df_train[\"label\"].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "dev_dataset = TokenClassificationDataset(\n",
    "    ids=df_dev[\"id\"].values,\n",
    "    texts=df_dev[\"text\"].values,\n",
    "    targets=df_dev[\"label\"].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "test_dataset = TokenClassificationDataset(\n",
    "    ids=df_test[\"id\"].values,\n",
    "    texts=df_test[\"text\"].values,\n",
    "    targets=df_test[\"label\"].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config[\"data\"][\"max_len\"],\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "dev_dataloader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config[\"data\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(train_dataloader):\n",
    "#     print(f\"Batch=[{i + 1}/{len(train_dataloader)}]\")\n",
    "#     # break\n",
    "\n",
    "# for i, batch in enumerate(dev_dataloader):\n",
    "#     print(f\"Batch=[{i + 1}/{len(dev_dataloader)}]\")\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LongformerBiLSTM model for token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import LongformerModel\n",
    "\n",
    "\n",
    "class LongformerBiLSTMForTokenClassification(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model_name,\n",
    "        out_size,\n",
    "        device,\n",
    "        dropout_p=0.3,\n",
    "        last_layers_emb=4,\n",
    "        hidden_dim=200,\n",
    "        fc=[],\n",
    "        finetune_last_layers_emb=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_size = out_size\n",
    "        self.device = device\n",
    "        self.last_layers_emb = last_layers_emb\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.finetune_last_layers_emb = finetune_last_layers_emb\n",
    "\n",
    "        self.longformer = LongformerModel.from_pretrained(\n",
    "            pretrained_model_name, return_dict=False, output_hidden_states=True,\n",
    "        )\n",
    "\n",
    "        embedding_dim = last_layers_emb * self.longformer.config.hidden_size\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "#         self.classifier = nn.Linear(2 * hidden_dim, out_size)\n",
    "        self.classifier = sequential_fully_connected(\n",
    "            2 * hidden_dim, out_size, fc, dropout_p\n",
    "        )\n",
    "\n",
    "        self.freeze_transformer_layer()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.longformer(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_states = outputs[2]\n",
    "        # print(f\"hidden_states: {hidden_states}\")\n",
    "\n",
    "        embeddings = hidden_states[-self.last_layers_emb :]\n",
    "        # print(f\"embeddings.shape: {embeddings.shape}\")\n",
    "\n",
    "        # embeddings: (batch_size, max_seq_len, last_layers_emb * hidden_size)\n",
    "        embeddings = torch.cat(embeddings, dim=2)\n",
    "        # print(f\"embeddings.shape: {embeddings.shape}\")\n",
    "\n",
    "        lengths = attention_mask.sum(dim=1)\n",
    "        # print(f\"lengths.shape: {lengths.shape}\")\n",
    "\n",
    "        packed_embeddings = nn.utils.rnn.pack_padded_sequence(\n",
    "            embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        # print(f\"packed_embeddings.data.shape: {packed_embeddings.data.shape}\")\n",
    "\n",
    "        packed_output, (_, _) = self.lstm(packed_embeddings)\n",
    "        # print(f\"packed_output.data.shape: {packed_output.data.shape}\")\n",
    "\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_output, batch_first=True, total_length=embeddings.shape[1],\n",
    "        )\n",
    "        # print(f\"output.shape: {output.shape}\")\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss().to(self.device)\n",
    "            loss = loss_fn(logits.view(-1, self.out_size), labels.view(-1))\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "    def freeze_transformer_layer(self):\n",
    "        for param in self.longformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_transformer_layer(self):\n",
    "        if self.finetune_last_layers_emb:\n",
    "            # print(f\"Will fine-tune last {self.last_layers_emb} layers\")\n",
    "            # Fine-tune only the last emb layers\n",
    "#             for layer in self.longformer.encoder.layer[-self.last_layers_emb :]:\n",
    "            for layer in self.longformer.encoder.layer[-1:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "        else:\n",
    "            # Do nothing\n",
    "            # print(f\"Transformer used as feature extractor only => no fine-tuning\")\n",
    "            pass\n",
    "\n",
    "    def get_predictions_from_logits(self, logits, labels=None, corresponding_word=None):\n",
    "        batch_size = logits.shape[0]\n",
    "\n",
    "        # logits: (batch_size, max_seq_len, out_size)\n",
    "        # labels: (batch_size, max_seq_len)\n",
    "        # corresponding_word: (batch_size, max_seq_len)\n",
    "\n",
    "        # print(f\"logits.shape: {logits.shape}\")\n",
    "        # print(f\"logits: {logits}\")\n",
    "\n",
    "        # preds: (batch_size, max_seq_len)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # print(f\"preds.shape: {preds.shape}\")\n",
    "        # print(f\"preds: {preds}\")\n",
    "\n",
    "        if labels is not None:\n",
    "            # print(f\"labels.shape: {labels.shape}\")\n",
    "            # print(f\"labels: {labels}\")\n",
    "\n",
    "            # Keep only predictions where labels are not -100\n",
    "            # clean_preds = preds[labels != -100].reshape(batch_size, -1)\n",
    "            # clean_labels = labels[labels != -100].reshape(batch_size, -1)\n",
    "\n",
    "            # print(f\"clean_preds.shape: {clean_preds.shape}\")\n",
    "            # print(f\"clean_preds: {clean_preds}\")\n",
    "\n",
    "            # print(f\"clean_labels.shape: {clean_labels.shape}\")\n",
    "            # print(f\"clean_labels: {clean_labels}\")\n",
    "\n",
    "            # Get the index of the first machine text word\n",
    "            # predicted_positions = clean_preds.argmax(dim=-1)\n",
    "            # true_positions = clean_labels.argmax(dim=-1)\n",
    "\n",
    "            predicted_positions = []\n",
    "            true_positions = []\n",
    "            for p, l in zip(preds, labels):\n",
    "                mask = l != -100\n",
    "\n",
    "                clean_pred = p[mask]\n",
    "                clean_label = l[mask]\n",
    "\n",
    "                # print(f\"clean_pred.shape: {clean_pred.shape}\")\n",
    "                # print(f\"clean_pred: {clean_pred}\")\n",
    "                # print(f\"clean_label.shape: {clean_label.shape}\")\n",
    "                # print(f\"clean_label: {clean_label}\")\n",
    "\n",
    "                predicted_position = clean_pred.argmax(dim=-1)\n",
    "                true_position = clean_label.argmax(dim=-1)\n",
    "\n",
    "                # print(f\"predicted_position: {predicted_position}\")\n",
    "                # print(f\"true_position: {true_position}\")\n",
    "\n",
    "                predicted_positions.append(predicted_position.item())\n",
    "                true_positions.append(true_position.item())\n",
    "\n",
    "            # print(f\"predicted_positions.shape: {predicted_positions.shape}\")\n",
    "            # print(f\"predicted_positions: {predicted_positions}\")\n",
    "\n",
    "            # print(f\"true_positions.shape: {true_positions.shape}\")\n",
    "            # print(f\"true_positions: {true_positions}\")\n",
    "\n",
    "            # print(f\"predicted_positions type: {type(predicted_positions)}\")\n",
    "            # print(f\"true_positions type: {type(true_positions)}\")\n",
    "\n",
    "            return torch.Tensor(predicted_positions), torch.Tensor(true_positions)\n",
    "        elif corresponding_word is not None:\n",
    "            # print(f\"corresponding_word.shape: {corresponding_word.shape}\")\n",
    "            # print(f\"corresponding_word: {corresponding_word}\")\n",
    "\n",
    "            # Keep only predictions where corresponding_word are not -100\n",
    "            # clean_preds = preds[corresponding_word != -100].reshape(\n",
    "            #     batch_size, -1\n",
    "            # ).detach().cpu().numpy()\n",
    "            # clean_corresponding_word = corresponding_word[corresponding_word != -100].reshape(\n",
    "            #     batch_size, -1\n",
    "            # ).detach().cpu().numpy()\n",
    "\n",
    "            # print(f\"clean_preds.shape: {clean_preds.shape}\")\n",
    "            # print(f\"clean_preds: {clean_preds}\")\n",
    "\n",
    "            # print(f\"clean_corresponding_word.shape: {clean_corresponding_word.shape}\")\n",
    "            # print(f\"clean_corresponding_word: {clean_corresponding_word}\")\n",
    "\n",
    "            predicted_positions = []\n",
    "            for p, w in zip(preds, corresponding_word):\n",
    "                mask = w != -100\n",
    "\n",
    "                clean_pred = p[mask]\n",
    "                clean_corresponding_word = w[mask]\n",
    "\n",
    "                # print(f\"clean_pred.shape: {clean_pred.shape}\")\n",
    "                # print(f\"clean_pred: {clean_pred}\")\n",
    "                # print(f\"clean_corresponding_word.shape: {clean_corresponding_word.shape}\")\n",
    "                # print(f\"clean_corresponding_word: {clean_corresponding_word}\")\n",
    "\n",
    "                # Get the index of the first machine text word\n",
    "                index = torch.where(clean_pred == 1)[0]\n",
    "                value = index[0] if index.size else len(clean_pred) - 1\n",
    "                position = clean_corresponding_word[value]\n",
    "\n",
    "                # print(f\"index: {index}\")\n",
    "                # print(f\"value: {value}\")\n",
    "                # print(f\"position: {position}\")\n",
    "\n",
    "                predicted_positions.append(position.item())\n",
    "            #     # pred = pred.detach().cpu().numpy()\n",
    "\n",
    "            #     index = np.where(pred == 1)[0]\n",
    "            #     value = index[0] if index.size else len(pred) - 1\n",
    "            #     position = clean_corresponding_word[idx][value]\n",
    "\n",
    "            #     predicted_positions.append(position.item())\n",
    "\n",
    "            print(f\"predicted_positions: {predicted_positions}\")\n",
    "\n",
    "            return predicted_positions, None\n",
    "        else:\n",
    "            raise ValueError(\"Either labels or corresponding_word must be provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    metric_fn,\n",
    "    print_freq=10,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        ids = batch[\"id\"]\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"target\"].to(device)\n",
    "        corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "        loss, logits = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=targets,\n",
    "        )\n",
    "\n",
    "        predictions, true_predictions = model.get_predictions_from_logits(\n",
    "            logits=logits,\n",
    "            labels=targets,\n",
    "            corresponding_word=corresponding_word\n",
    "        )\n",
    "\n",
    "        # print(f\"predictions: {predictions}\")\n",
    "        # print(f\"true_predictions: {true_predictions}\")\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        all_predictions.extend(predictions.tolist())\n",
    "        all_true.extend(true_predictions.tolist())\n",
    "        all_ids.extend(ids)\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(\n",
    "                f\"Batch [{i + 1}/{len(dataloader)}]; \"\n",
    "                f\"Loss: {loss.item():.5f}; \"\n",
    "                f\"Mean absolute error: {metric_fn(true_predictions, predictions):.5f}\"\n",
    "            )\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return np.mean(losses), (all_ids, all_true, all_predictions)\n",
    "\n",
    "\n",
    "def validation_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    metric_fn,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            ids = batch[\"id\"]\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "            corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "            loss, logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=targets,\n",
    "            )\n",
    "\n",
    "            predictions, true_predictions = model.get_predictions_from_logits(\n",
    "                logits=logits,\n",
    "                labels=targets,\n",
    "                corresponding_word=corresponding_word\n",
    "            )\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            all_true.extend(true_predictions.tolist())\n",
    "            all_ids.extend(ids)\n",
    "\n",
    "    return np.mean(losses), (all_ids, all_true, all_predictions)\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer_config,\n",
    "    scheduler_config,\n",
    "    device,\n",
    "    metric_fn,\n",
    "    is_better_metric_fn,\n",
    "    num_epochs_before_finetune,\n",
    "    results_dir,\n",
    "):\n",
    "    history = defaultdict(list)\n",
    "    best_metric = None\n",
    "    best_model_state = None\n",
    "\n",
    "    optimizer = get_optimizer(model, optimizer_config, finetune=False)\n",
    "    scheduler = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        if epoch <= num_epochs_before_finetune:\n",
    "            print(\"Freeze transformer\")\n",
    "        else:\n",
    "            print(\"Finetune transformer\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        if epoch == num_epochs_before_finetune + 1:\n",
    "            model.unfreeze_transformer_layer()\n",
    "            optimizer = get_optimizer(model, optimizer_config, finetune=True)\n",
    "            scheduler = get_scheduler(\n",
    "                optimizer,\n",
    "                num_training_steps=len(train_dataloader) * num_epochs,\n",
    "                **scheduler_config,\n",
    "            )\n",
    "\n",
    "        train_loss, (train_ids, train_true, train_predict) = train_epoch(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            device,\n",
    "            scheduler,\n",
    "            metric_fn,\n",
    "        )\n",
    "\n",
    "        train_metric = metric_fn(train_true, train_predict)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.5f}; Train Metric: {train_metric:.5f}\")\n",
    "\n",
    "        dev_loss, (dev_ids, dev_true, dev_predict) = validation_epoch(\n",
    "            model,\n",
    "            dev_dataloader,\n",
    "            loss_fn,\n",
    "            device,\n",
    "            metric_fn,\n",
    "        )\n",
    "\n",
    "        dev_metric = metric_fn(dev_true, dev_predict)\n",
    "\n",
    "        print(\n",
    "            f\"Validation Loss: {dev_loss:.5f}; \"\n",
    "            f\"Validation Metric: {dev_metric:.5f}\"\n",
    "        )\n",
    "\n",
    "        history[\"train_metric\"].append(train_metric)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"dev_metric\"].append(dev_metric)\n",
    "        history[\"dev_loss\"].append(dev_loss)\n",
    "\n",
    "        if best_metric is None or is_better_metric_fn(train_metric, best_metric):\n",
    "            best_metric = train_metric\n",
    "            best_model_state = model.state_dict()\n",
    "            \n",
    "            if results_dir is not None:\n",
    "                torch.save(\n",
    "                    best_model_state,\n",
    "                    os.path.join(results_dir, \"best_model.bin\"),\n",
    "                )\n",
    "\n",
    "                df_train_predictions = pd.DataFrame(\n",
    "                    {\n",
    "                        \"id\": train_ids,\n",
    "                        \"true\": train_true,\n",
    "                        \"predict\": train_predict,\n",
    "                    }\n",
    "                )\n",
    "                df_train_predictions.to_csv(\n",
    "                    os.path.join(results_dir, \"best_model_train_predict.csv\"),\n",
    "                    index=False\n",
    "                )\n",
    "\n",
    "                df_dev_predictions = pd.DataFrame(\n",
    "                    {\n",
    "                        \"id\": dev_ids,\n",
    "                        \"true\": dev_true,\n",
    "                        \"predict\": dev_predict,\n",
    "                    }\n",
    "                )\n",
    "                df_dev_predictions.to_csv(\n",
    "                    os.path.join(results_dir, \"best_model_dev_predict.csv\"),\n",
    "                    index=False\n",
    "                )\n",
    "\n",
    "    df_history = pd.DataFrame(history)\n",
    "    if results_dir is not None:\n",
    "        df_history.to_csv(os.path.join(results_dir, \"history.csv\"), index=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(results_dir, \"best_model.bin\")))\n",
    "    else:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model, df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.84567; Mean absolute error: 72.03125\n",
      "Batch [11/92]; Loss: 0.46727; Mean absolute error: 103.31250\n",
      "Batch [21/92]; Loss: 0.29498; Mean absolute error: 41.18750\n",
      "Batch [31/92]; Loss: 0.19255; Mean absolute error: 44.28125\n",
      "Batch [41/92]; Loss: 0.20362; Mean absolute error: 40.81250\n",
      "Batch [51/92]; Loss: 0.14458; Mean absolute error: 27.03125\n",
      "Batch [61/92]; Loss: 0.18996; Mean absolute error: 20.28125\n",
      "Batch [71/92]; Loss: 0.12622; Mean absolute error: 14.37500\n",
      "Batch [81/92]; Loss: 0.14130; Mean absolute error: 11.87500\n",
      "Batch [91/92]; Loss: 0.12274; Mean absolute error: 18.12500\n",
      "Train Loss: 0.26239; Train Metric: 44.49469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13114; Validation Metric: 19.40137\n",
      "Epoch 2/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.09140; Mean absolute error: 12.15625\n",
      "Batch [11/92]; Loss: 0.08971; Mean absolute error: 10.75000\n",
      "Batch [21/92]; Loss: 0.11847; Mean absolute error: 18.93750\n",
      "Batch [31/92]; Loss: 0.09492; Mean absolute error: 16.78125\n",
      "Batch [41/92]; Loss: 0.33100; Mean absolute error: 22.28125\n",
      "Batch [51/92]; Loss: 0.08187; Mean absolute error: 10.62500\n",
      "Batch [61/92]; Loss: 0.09596; Mean absolute error: 17.21875\n",
      "Batch [71/92]; Loss: 0.08397; Mean absolute error: 14.43750\n",
      "Batch [81/92]; Loss: 0.06899; Mean absolute error: 13.96875\n",
      "Batch [91/92]; Loss: 0.17210; Mean absolute error: 35.15625\n",
      "Train Loss: 0.10168; Train Metric: 16.34943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.14549; Validation Metric: 22.44932\n",
      "Epoch 3/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.08393; Mean absolute error: 13.09375\n",
      "Batch [11/92]; Loss: 0.14445; Mean absolute error: 16.62500\n",
      "Batch [21/92]; Loss: 0.06803; Mean absolute error: 10.31250\n",
      "Batch [31/92]; Loss: 0.06224; Mean absolute error: 13.46875\n",
      "Batch [41/92]; Loss: 0.05307; Mean absolute error: 8.46875\n",
      "Batch [51/92]; Loss: 0.16532; Mean absolute error: 20.12500\n",
      "Batch [61/92]; Loss: 0.05636; Mean absolute error: 7.78125\n",
      "Batch [71/92]; Loss: 0.23875; Mean absolute error: 29.78125\n",
      "Batch [81/92]; Loss: 0.06318; Mean absolute error: 10.62500\n",
      "Batch [91/92]; Loss: 0.11329; Mean absolute error: 30.12500\n",
      "Train Loss: 0.08104; Train Metric: 13.32066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.10241; Validation Metric: 14.45342\n",
      "Epoch 4/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.06812; Mean absolute error: 7.71875\n",
      "Batch [11/92]; Loss: 0.06843; Mean absolute error: 8.62500\n",
      "Batch [21/92]; Loss: 0.06917; Mean absolute error: 15.65625\n",
      "Batch [31/92]; Loss: 0.08665; Mean absolute error: 10.09375\n",
      "Batch [41/92]; Loss: 0.09537; Mean absolute error: 9.68750\n",
      "Batch [51/92]; Loss: 0.07508; Mean absolute error: 10.75000\n",
      "Batch [61/92]; Loss: 0.07319; Mean absolute error: 12.03125\n",
      "Batch [71/92]; Loss: 0.03224; Mean absolute error: 4.50000\n",
      "Batch [81/92]; Loss: 0.05710; Mean absolute error: 8.09375\n",
      "Batch [91/92]; Loss: 0.05125; Mean absolute error: 8.78125\n",
      "Train Loss: 0.07390; Train Metric: 11.86776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.12724; Validation Metric: 16.44658\n",
      "Epoch 5/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.14245; Mean absolute error: 13.21875\n",
      "Batch [11/92]; Loss: 0.04852; Mean absolute error: 8.18750\n",
      "Batch [21/92]; Loss: 0.07465; Mean absolute error: 19.96875\n",
      "Batch [31/92]; Loss: 0.04294; Mean absolute error: 5.90625\n",
      "Batch [41/92]; Loss: 0.09929; Mean absolute error: 12.53125\n",
      "Batch [51/92]; Loss: 0.02988; Mean absolute error: 3.56250\n",
      "Batch [61/92]; Loss: 0.03409; Mean absolute error: 11.00000\n",
      "Batch [71/92]; Loss: 0.07028; Mean absolute error: 10.00000\n",
      "Batch [81/92]; Loss: 0.07778; Mean absolute error: 10.25000\n",
      "Batch [91/92]; Loss: 0.05436; Mean absolute error: 8.03125\n",
      "Train Loss: 0.06393; Train Metric: 10.11168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.23503; Validation Metric: 32.68356\n",
      "Epoch 6/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.07740; Mean absolute error: 19.71875\n",
      "Batch [11/92]; Loss: 0.08504; Mean absolute error: 24.87500\n",
      "Batch [21/92]; Loss: 0.05042; Mean absolute error: 18.90625\n",
      "Batch [31/92]; Loss: 0.05729; Mean absolute error: 14.25000\n",
      "Batch [41/92]; Loss: 0.03995; Mean absolute error: 7.75000\n",
      "Batch [51/92]; Loss: 0.04020; Mean absolute error: 5.31250\n",
      "Batch [61/92]; Loss: 0.04621; Mean absolute error: 7.31250\n",
      "Batch [71/92]; Loss: 0.04782; Mean absolute error: 10.90625\n",
      "Batch [81/92]; Loss: 0.03971; Mean absolute error: 7.87500\n",
      "Batch [91/92]; Loss: 0.04272; Mean absolute error: 4.65625\n",
      "Train Loss: 0.05536; Train Metric: 9.36245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.12892; Validation Metric: 15.88219\n",
      "Epoch 7/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.03400; Mean absolute error: 5.40625\n",
      "Batch [11/92]; Loss: 0.05228; Mean absolute error: 10.18750\n",
      "Batch [21/92]; Loss: 0.07395; Mean absolute error: 9.53125\n",
      "Batch [31/92]; Loss: 0.03430; Mean absolute error: 3.65625\n",
      "Batch [41/92]; Loss: 0.03255; Mean absolute error: 4.12500\n",
      "Batch [51/92]; Loss: 0.04520; Mean absolute error: 5.28125\n",
      "Batch [61/92]; Loss: 0.05377; Mean absolute error: 6.25000\n",
      "Batch [71/92]; Loss: 0.03979; Mean absolute error: 6.12500\n",
      "Batch [81/92]; Loss: 0.06767; Mean absolute error: 9.59375\n",
      "Batch [91/92]; Loss: 0.06425; Mean absolute error: 14.28125\n",
      "Train Loss: 0.04636; Train Metric: 7.74854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.16404; Validation Metric: 23.12329\n",
      "Epoch 8/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.04803; Mean absolute error: 8.81250\n",
      "Batch [11/92]; Loss: 0.03732; Mean absolute error: 7.15625\n",
      "Batch [21/92]; Loss: 0.06730; Mean absolute error: 11.68750\n",
      "Batch [31/92]; Loss: 0.03315; Mean absolute error: 5.53125\n",
      "Batch [41/92]; Loss: 0.03275; Mean absolute error: 4.87500\n",
      "Batch [51/92]; Loss: 0.02942; Mean absolute error: 4.59375\n",
      "Batch [61/92]; Loss: 0.03921; Mean absolute error: 6.18750\n",
      "Batch [71/92]; Loss: 0.02641; Mean absolute error: 4.00000\n",
      "Batch [81/92]; Loss: 0.03521; Mean absolute error: 3.53125\n",
      "Batch [91/92]; Loss: 0.03618; Mean absolute error: 6.12500\n",
      "Train Loss: 0.04123; Train Metric: 6.73929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.11267; Validation Metric: 12.80959\n",
      "Epoch 9/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.04946; Mean absolute error: 6.15625\n",
      "Batch [11/92]; Loss: 0.02857; Mean absolute error: 4.34375\n",
      "Batch [21/92]; Loss: 0.03764; Mean absolute error: 5.90625\n",
      "Batch [31/92]; Loss: 0.04730; Mean absolute error: 6.50000\n",
      "Batch [41/92]; Loss: 0.03463; Mean absolute error: 7.56250\n",
      "Batch [51/92]; Loss: 0.03263; Mean absolute error: 4.53125\n",
      "Batch [61/92]; Loss: 0.02952; Mean absolute error: 3.62500\n",
      "Batch [71/92]; Loss: 0.03091; Mean absolute error: 4.65625\n",
      "Batch [81/92]; Loss: 0.02987; Mean absolute error: 5.00000\n",
      "Batch [91/92]; Loss: 0.02519; Mean absolute error: 5.25000\n",
      "Train Loss: 0.03403; Train Metric: 5.64406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.12558; Validation Metric: 14.64384\n",
      "Epoch 10/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.02589; Mean absolute error: 4.00000\n",
      "Batch [11/92]; Loss: 0.02143; Mean absolute error: 2.90625\n",
      "Batch [21/92]; Loss: 0.03899; Mean absolute error: 6.87500\n",
      "Batch [31/92]; Loss: 0.03685; Mean absolute error: 19.03125\n",
      "Batch [41/92]; Loss: 0.03808; Mean absolute error: 6.65625\n",
      "Batch [51/92]; Loss: 0.02449; Mean absolute error: 6.75000\n",
      "Batch [61/92]; Loss: 0.02226; Mean absolute error: 5.00000\n",
      "Batch [71/92]; Loss: 0.02616; Mean absolute error: 3.71875\n",
      "Batch [81/92]; Loss: 0.03138; Mean absolute error: 6.68750\n",
      "Batch [91/92]; Loss: 0.02850; Mean absolute error: 3.75000\n",
      "Train Loss: 0.03032; Train Metric: 5.38335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.12239; Validation Metric: 14.40411\n",
      "Epoch 11/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.02805; Mean absolute error: 5.06250\n",
      "Batch [11/92]; Loss: 0.02559; Mean absolute error: 2.59375\n",
      "Batch [21/92]; Loss: 0.02320; Mean absolute error: 3.75000\n",
      "Batch [31/92]; Loss: 0.02783; Mean absolute error: 4.78125\n",
      "Batch [41/92]; Loss: 0.02631; Mean absolute error: 4.53125\n",
      "Batch [51/92]; Loss: 0.03409; Mean absolute error: 4.28125\n",
      "Batch [61/92]; Loss: 0.02341; Mean absolute error: 3.78125\n",
      "Batch [71/92]; Loss: 0.02386; Mean absolute error: 4.03125\n",
      "Batch [81/92]; Loss: 0.02560; Mean absolute error: 3.56250\n",
      "Batch [91/92]; Loss: 0.03294; Mean absolute error: 5.96875\n",
      "Train Loss: 0.02754; Train Metric: 4.96471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.15649; Validation Metric: 15.35205\n",
      "Epoch 12/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.01696; Mean absolute error: 2.65625\n",
      "Batch [11/92]; Loss: 0.01751; Mean absolute error: 3.31250\n",
      "Batch [21/92]; Loss: 0.03636; Mean absolute error: 17.12500\n",
      "Batch [31/92]; Loss: 0.01944; Mean absolute error: 2.81250\n",
      "Batch [41/92]; Loss: 0.02025; Mean absolute error: 2.75000\n",
      "Batch [51/92]; Loss: 0.02124; Mean absolute error: 3.43750\n",
      "Batch [61/92]; Loss: 0.02607; Mean absolute error: 2.90625\n",
      "Batch [71/92]; Loss: 0.02710; Mean absolute error: 3.46875\n",
      "Batch [81/92]; Loss: 0.02494; Mean absolute error: 4.00000\n",
      "Batch [91/92]; Loss: 0.03011; Mean absolute error: 9.06250\n",
      "Train Loss: 0.02376; Train Metric: 4.36519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.17035; Validation Metric: 16.47260\n",
      "Epoch 13/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.02246; Mean absolute error: 4.87500\n",
      "Batch [11/92]; Loss: 0.02057; Mean absolute error: 3.46875\n",
      "Batch [21/92]; Loss: 0.01682; Mean absolute error: 2.21875\n",
      "Batch [31/92]; Loss: 0.02800; Mean absolute error: 2.81250\n",
      "Batch [41/92]; Loss: 0.02249; Mean absolute error: 3.21875\n",
      "Batch [51/92]; Loss: 0.01658; Mean absolute error: 2.43750\n",
      "Batch [61/92]; Loss: 0.03899; Mean absolute error: 22.37500\n",
      "Batch [71/92]; Loss: 0.02378; Mean absolute error: 3.56250\n",
      "Batch [81/92]; Loss: 0.01800; Mean absolute error: 5.09375\n",
      "Batch [91/92]; Loss: 0.02176; Mean absolute error: 3.00000\n",
      "Train Loss: 0.02070; Train Metric: 3.81877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.14790; Validation Metric: 13.18082\n",
      "Epoch 14/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.01466; Mean absolute error: 2.62500\n",
      "Batch [11/92]; Loss: 0.01633; Mean absolute error: 3.15625\n",
      "Batch [21/92]; Loss: 0.01943; Mean absolute error: 2.71875\n",
      "Batch [31/92]; Loss: 0.01420; Mean absolute error: 3.03125\n",
      "Batch [41/92]; Loss: 0.01880; Mean absolute error: 3.21875\n",
      "Batch [51/92]; Loss: 0.01921; Mean absolute error: 2.68750\n",
      "Batch [61/92]; Loss: 0.01932; Mean absolute error: 2.93750\n",
      "Batch [71/92]; Loss: 0.01919; Mean absolute error: 2.18750\n",
      "Batch [81/92]; Loss: 0.01550; Mean absolute error: 3.65625\n",
      "Batch [91/92]; Loss: 0.01291; Mean absolute error: 2.09375\n",
      "Train Loss: 0.01853; Train Metric: 3.48338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.15630; Validation Metric: 13.96438\n",
      "Epoch 15/15\n",
      "Finetune transformer\n",
      "----------\n",
      "Batch [1/92]; Loss: 0.02044; Mean absolute error: 3.25000\n",
      "Batch [11/92]; Loss: 0.01839; Mean absolute error: 4.78125\n",
      "Batch [21/92]; Loss: 0.01729; Mean absolute error: 2.21875\n",
      "Batch [31/92]; Loss: 0.02009; Mean absolute error: 2.81250\n",
      "Batch [41/92]; Loss: 0.01580; Mean absolute error: 2.62500\n",
      "Batch [51/92]; Loss: 0.01715; Mean absolute error: 2.56250\n",
      "Batch [61/92]; Loss: 0.01480; Mean absolute error: 2.21875\n",
      "Batch [71/92]; Loss: 0.01571; Mean absolute error: 1.53125\n",
      "Batch [81/92]; Loss: 0.02114; Mean absolute error: 2.68750\n",
      "Batch [91/92]; Loss: 0.01828; Mean absolute error: 3.43750\n",
      "Train Loss: 0.01703; Train Metric: 3.04967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:34<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.15478; Validation Metric: 13.62055\n"
     ]
    }
   ],
   "source": [
    "num_epochs = config[\"training\"][\"num_epochs\"]\n",
    "model = LongformerBiLSTMForTokenClassification(\n",
    "    device=DEVICE, **config[\"model_config\"]\n",
    ").to(DEVICE)\n",
    "loss_fn = get_loss_fn(config[\"training\"][\"loss\"], DEVICE)\n",
    "optimizer_config = config[\"training\"][\"optimizer\"]\n",
    "scheduler_config = config[\"training\"][\"scheduler\"]\n",
    "metric_fn, is_better_metric_fn = get_metric(config[\"training\"][\"metric\"])\n",
    "num_epochs_before_finetune = config[\"training\"][\"num_epochs_before_finetune\"]\n",
    "\n",
    "best_model, df_history = training_loop(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer_config,\n",
    "    scheduler_config,\n",
    "    DEVICE,\n",
    "    metric_fn,\n",
    "    is_better_metric_fn,\n",
    "    num_epochs_before_finetune,\n",
    "    results_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def make_predictions(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    results_dir,\n",
    "    label_column,\n",
    "    file_format=\"csv\",\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            ids = batch[\"id\"]\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "            corresponding_word = batch[\"corresponding_word\"].to(device)\n",
    "\n",
    "            _, logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=targets,\n",
    "            )\n",
    "\n",
    "            predictions, true_predictions = model.get_predictions_from_logits(\n",
    "                logits=logits,\n",
    "                labels=targets,\n",
    "                corresponding_word=corresponding_word\n",
    "            )\n",
    "\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            all_true.extend(true_predictions.tolist())\n",
    "            all_ids.extend(ids)\n",
    "\n",
    "    df_predictions = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": all_ids,\n",
    "            \"true\": all_true,\n",
    "            label_column: all_predictions,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if results_dir is not None:\n",
    "        if file_format == \"csv\":\n",
    "            df_predictions.to_csv(\n",
    "                os.path.join(results_dir, \"submission.csv\"),\n",
    "                index=False,\n",
    "            )\n",
    "        elif file_format == \"jsonl\":\n",
    "            df_predictions.to_json(\n",
    "                os.path.join(results_dir, \"submission.jsonl\"),\n",
    "                orient=\"records\",\n",
    "                lines=True,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown file format: {file_format}\")\n",
    "    else:\n",
    "        print(\"Missing results_dir, not saving predictions to file!\")\n",
    "\n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:23<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = make_predictions(\n",
    "    best_model,\n",
    "    test_dataloader,\n",
    "    DEVICE,\n",
    "    results_dir,\n",
    "    config[\"data\"][\"label_column\"],\n",
    "    file_format=\"csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation\n",
      "MAE: 13.62055\n",
      "--------------------\n",
      "Results on test\n",
      "MAE: 11.25149\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "!python ../scores_and_plots.py --results-dir \"../runs/29-12-2023_13:41:34-SubtaskC-longformer_bilstm\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

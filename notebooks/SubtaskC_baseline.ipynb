{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmarchitan/Developer/ml_research/machine-generated_text_detection/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers.trainer_callback import TrainerState\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, List, Optional\n",
    "import logging\n",
    "import glob\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Semeval_Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, max_length=1024, inference=False, debug=False):\n",
    "        with open(data_path, \"r\") as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "        self.inference = inference\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "        self.max_length = max_length\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx][\"text\"]\n",
    "        id = self.data[idx][\"id\"]\n",
    "        label = None\n",
    "        labels_available = \"label\" in self.data[idx]\n",
    "\n",
    "        if labels_available:\n",
    "            label = self.data[idx][\"label\"]\n",
    "\n",
    "        if self.debug and not self.inference:\n",
    "            print(\"Orignal Human Position: \", label)\n",
    "\n",
    "        labels = []\n",
    "        corresponding_word = []\n",
    "        tokens = []\n",
    "        input_ids = []\n",
    "        attention_mask = []\n",
    "\n",
    "        for jdx, word in enumerate(text.split(\" \")):\n",
    "            word_encoded = self.tokenizer.tokenize(word)\n",
    "            sub_words = len(word_encoded)\n",
    "\n",
    "            if labels_available:\n",
    "                is_machine_text = 1 if jdx >= label else 0\n",
    "                labels.extend([is_machine_text] * sub_words)\n",
    "\n",
    "            corresponding_word.extend([jdx] * sub_words)\n",
    "            tokens.extend(word_encoded)\n",
    "            input_ids.extend(self.tokenizer.convert_tokens_to_ids(word_encoded))\n",
    "            attention_mask.extend([1] * sub_words)\n",
    "\n",
    "        ###Add padding to labels as -100\n",
    "        if len(input_ids) < self.max_length - 2:\n",
    "            input_ids = (\n",
    "                [0] + input_ids + [2] + [1] * (self.max_length - len(input_ids) - 2)\n",
    "            )\n",
    "            if labels_available:\n",
    "                labels = [-100] + labels + [-100] * (self.max_length - len(labels) - 1)\n",
    "\n",
    "            attention_mask = (\n",
    "                [1]\n",
    "                + attention_mask\n",
    "                + [1]\n",
    "                + [0] * (self.max_length - len(attention_mask) - 2)\n",
    "            )\n",
    "            corresponding_word = (\n",
    "                [-100]\n",
    "                + corresponding_word\n",
    "                + [-100] * (self.max_length - len(corresponding_word) - 1)\n",
    "            )\n",
    "            tokens = (\n",
    "                [\"<s>\"]\n",
    "                + tokens\n",
    "                + [\"</s>\"]\n",
    "                + [\"<pad>\"] * (self.max_length - len(tokens) - 2)\n",
    "            )\n",
    "        else:\n",
    "            # Add -100 for CLS and SEP tokens\n",
    "            input_ids = [0] + input_ids[: self.max_length - 2] + [2]\n",
    "\n",
    "            if labels_available:\n",
    "                labels = [-100] + labels[: self.max_length - 2] + [-100]\n",
    "\n",
    "            corresponding_word = (\n",
    "                [-100] + corresponding_word[: self.max_length - 2] + [-100]\n",
    "            )\n",
    "            attention_mask = [1] + attention_mask[: self.max_length - 2] + [1]\n",
    "            tokens = [\"<s>\"] + tokens[: self.max_length - 2] + [\"</s>\"]\n",
    "\n",
    "        encoded = {}\n",
    "        if labels_available:\n",
    "            encoded[\"labels\"] = torch.tensor(labels)\n",
    "\n",
    "        encoded[\"input_ids\"] = torch.tensor(input_ids)\n",
    "        encoded[\"attention_mask\"] = torch.tensor(attention_mask)\n",
    "\n",
    "        if labels_available:\n",
    "            if encoded[\"input_ids\"].shape != encoded[\"labels\"].shape:\n",
    "                print(\"Input IDs Shape: \", encoded[\"input_ids\"].shape)\n",
    "                print(\"Labels Shape: \", encoded[\"labels\"].shape)\n",
    "            assert encoded[\"input_ids\"].shape == encoded[\"labels\"].shape\n",
    "\n",
    "        if self.debug and not self.inference:\n",
    "            print(\"Tokenized Human Position: \", labels.index(1))\n",
    "            print(\"Original Human Position: \", label)\n",
    "            print(\"Full Human Text:\", text)\n",
    "            print(\"\\n\")\n",
    "            print(\"Human Text Truncated:\", text.split(\" \")[:label])\n",
    "            print(\"\\n\")\n",
    "            encoded[\"partial_human_review\"] = \" \".join(text.split(\" \")[:label])\n",
    "\n",
    "        if self.inference:\n",
    "            encoded[\"text\"] = text\n",
    "            encoded[\"id\"] = id\n",
    "            encoded[\"corresponding_word\"] = corresponding_word\n",
    "\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_position_difference(actual_position, predicted_position):\n",
    "    \"\"\"\n",
    "    Compute the absolute difference between the actual and predicted start positions.\n",
    "\n",
    "    Args:\n",
    "    - actual_position (int): Actual start position of machine-generated text.\n",
    "    - predicted_position (int): Predicted start position of machine-generated text.\n",
    "\n",
    "    Returns:\n",
    "    - int: Absolute difference between the start positions.\n",
    "    \"\"\"\n",
    "    return abs(actual_position - predicted_position)\n",
    "\n",
    "\n",
    "def get_start_position(sequence, mapping=None, token_level=True):\n",
    "    \"\"\"\n",
    "    Get the start position from a sequence of labels or predictions.\n",
    "\n",
    "    Args:\n",
    "    - sequence (np.array): A sequence of labels or predictions.\n",
    "    - mapping (np.array): Mapping from index to word for the sequence.\n",
    "    - token_level (bool): If True, return positional indices; else, return word mappings.\n",
    "\n",
    "    Returns:\n",
    "    - int or str: Start position in the sequence.\n",
    "    \"\"\"\n",
    "    # Locate the position of label '1'\n",
    "\n",
    "    if mapping is not None:\n",
    "        mask = mapping != -100\n",
    "        sequence = sequence[mask]\n",
    "        mapping = mapping[mask]\n",
    "\n",
    "    index = np.where(sequence == 1)[0]\n",
    "    value = index[0] if index.size else (len(sequence) - 1)\n",
    "\n",
    "    if not token_level:\n",
    "        value = mapping[value]\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def evaluate_machine_start_position(\n",
    "    labels, predictions, idx2word=None, token_level=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the starting position of machine-generated text in both predicted and actual sequences.\n",
    "\n",
    "    Args:\n",
    "    - labels (np.array): Actual labels.\n",
    "    - predictions (np.array): Predicted labels.\n",
    "    - idx2word (np.array): Mapping from index to word for each sequence in the batch.\n",
    "    - token_level (bool): Flag to determine if evaluation is at token level. If True, return positional indices; else, return word mappings.\n",
    "\n",
    "    Returns:\n",
    "    - float: Mean absolute difference between the start positions in predictions and actual labels.\n",
    "    \"\"\"\n",
    "    predicted_positions = predictions.argmax(axis=-1)\n",
    "\n",
    "    actual_starts = []\n",
    "    predicted_starts = []\n",
    "\n",
    "    if not token_level and idx2word is None:\n",
    "        raise ValueError(\n",
    "            \"idx2word must be provided if evaluation is at word level (token_level=False)\"\n",
    "        )\n",
    "\n",
    "    for idx in range(labels.shape[0]):\n",
    "        # Remove padding\n",
    "        mask = labels[idx] != -100\n",
    "        predict, label, mapping = (\n",
    "            predicted_positions[idx][mask],\n",
    "            labels[idx][mask],\n",
    "            idx2word[idx][mask] if not token_level else None,\n",
    "        )\n",
    "\n",
    "        # If token_level is True, just use the index; otherwise, map to word\n",
    "        predicted_value = get_start_position(predict, mapping, token_level)\n",
    "        actual_value = get_start_position(label, mapping, token_level)\n",
    "\n",
    "        predicted_starts.append(predicted_value)\n",
    "        actual_starts.append(actual_value)\n",
    "\n",
    "    position_differences = [\n",
    "        evaluate_position_difference(actual, predict)\n",
    "        for actual, predict in zip(actual_starts, predicted_starts)\n",
    "    ]\n",
    "    mean_position_difference = np.mean(position_differences)\n",
    "\n",
    "    return mean_position_difference\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    mean_absolute_diff = evaluate_machine_start_position(labels, pred, token_level=True)\n",
    "\n",
    "    return {\n",
    "        \"mean_absolute_diff\": mean_absolute_diff,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--output_dir OUTPUT_DIR]\n",
      "                             [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
      "                             [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
      "                             [--do_predict [DO_PREDICT]]\n",
      "                             [--evaluation_strategy EVALUATION_STRATEGY]\n",
      "                             [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
      "                             [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                             [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                             [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
      "                             [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
      "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                             [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
      "                             [--eval_delay EVAL_DELAY]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "                             [--adam_beta1 ADAM_BETA1]\n",
      "                             [--adam_beta2 ADAM_BETA2]\n",
      "                             [--adam_epsilon ADAM_EPSILON]\n",
      "                             [--max_grad_norm MAX_GRAD_NORM]\n",
      "                             [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                             [--max_steps MAX_STEPS]\n",
      "                             [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt}]\n",
      "                             [--warmup_ratio WARMUP_RATIO]\n",
      "                             [--warmup_steps WARMUP_STEPS]\n",
      "                             [--log_level {debug,info,warning,error,critical,passive}]\n",
      "                             [--log_level_replica {debug,info,warning,error,critical,passive}]\n",
      "                             [--log_on_each_node [LOG_ON_EACH_NODE]]\n",
      "                             [--no_log_on_each_node]\n",
      "                             [--logging_dir LOGGING_DIR]\n",
      "                             [--logging_strategy {no,steps,epoch}]\n",
      "                             [--logging_first_step [LOGGING_FIRST_STEP]]\n",
      "                             [--logging_steps LOGGING_STEPS]\n",
      "                             [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
      "                             [--no_logging_nan_inf_filter]\n",
      "                             [--save_strategy SAVE_STRATEGY]\n",
      "                             [--save_steps SAVE_STEPS]\n",
      "                             [--save_total_limit SAVE_TOTAL_LIMIT]\n",
      "                             [--save_safetensors [SAVE_SAFETENSORS]]\n",
      "                             [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
      "                             [--no_cuda [NO_CUDA]]\n",
      "                             [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
      "                             [--data_seed DATA_SEED]\n",
      "                             [--jit_mode_eval [JIT_MODE_EVAL]]\n",
      "                             [--use_ipex [USE_IPEX]] [--bf16 [BF16]]\n",
      "                             [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]\n",
      "                             [--half_precision_backend {auto,cuda_amp,apex,cpu_amp}]\n",
      "                             [--bf16_full_eval [BF16_FULL_EVAL]]\n",
      "                             [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             [--xpu_backend {mpi,ccl,gloo}]\n",
      "                             [--tpu_num_cores TPU_NUM_CORES]\n",
      "                             [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
      "                             [--debug DEBUG]\n",
      "                             [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
      "                             [--eval_steps EVAL_STEPS]\n",
      "                             [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                             [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
      "                             [--disable_tqdm DISABLE_TQDM]\n",
      "                             [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
      "                             [--no_remove_unused_columns]\n",
      "                             [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                             [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
      "                             [--no_load_best_model_at_end]\n",
      "                             [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
      "                             [--greater_is_better GREATER_IS_BETTER]\n",
      "                             [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
      "                             [--sharded_ddp SHARDED_DDP] [--fsdp FSDP]\n",
      "                             [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
      "                             [--fsdp_config FSDP_CONFIG]\n",
      "                             [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
      "                             [--deepspeed DEEPSPEED]\n",
      "                             [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
      "                             [--optim {adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_apex_fused,adafactor,adamw_bnb_8bit,adamw_anyprecision,sgd,adagrad}]\n",
      "                             [--optim_args OPTIM_ARGS]\n",
      "                             [--adafactor [ADAFACTOR]]\n",
      "                             [--group_by_length [GROUP_BY_LENGTH]]\n",
      "                             [--length_column_name LENGTH_COLUMN_NAME]\n",
      "                             [--report_to REPORT_TO [REPORT_TO ...]]\n",
      "                             [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
      "                             [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
      "                             [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
      "                             [--no_dataloader_pin_memory]\n",
      "                             [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
      "                             [--no_skip_memory_metrics]\n",
      "                             [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
      "                             [--push_to_hub [PUSH_TO_HUB]]\n",
      "                             [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                             [--hub_model_id HUB_MODEL_ID]\n",
      "                             [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
      "                             [--hub_token HUB_TOKEN]\n",
      "                             [--hub_private_repo [HUB_PRIVATE_REPO]]\n",
      "                             [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
      "                             [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
      "                             [--fp16_backend {auto,cuda_amp,apex,cpu_amp}]\n",
      "                             [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
      "                             [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
      "                             [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
      "                             [--mp_parameters MP_PARAMETERS]\n",
      "                             [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
      "                             [--no_auto_find_batch_size]\n",
      "                             [--full_determinism [FULL_DETERMINISM]]\n",
      "                             [--torchdynamo TORCHDYNAMO]\n",
      "                             [--ray_scope RAY_SCOPE]\n",
      "                             [--ddp_timeout DDP_TIMEOUT]\n",
      "                             [--torch_compile [TORCH_COMPILE]]\n",
      "                             [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
      "                             [--torch_compile_mode TORCH_COMPILE_MODE]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/Users/tmarchitan/Library/Jupyter/runtime/kernel-v2-40369A6lg0htnSjWO.json could match --fp16, --fp16_opt_level, --fp16_full_eval, --fsdp, --fsdp_min_num_params, --fsdp_config, --fsdp_transformer_layer_cls_to_wrap, --fp16_backend, --full_determinism\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmarchitan/Developer/ml_research/machine-generated_text_detection/.env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3556: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class TrainingArgsConfig(transformers.TrainingArguments):\n",
    "    seed: int = 42\n",
    "    output_dir: str = \"../runs/SubtaskC_baseline\"\n",
    "    num_train_epochs: int = 10\n",
    "    per_device_train_batch_size: int = 32\n",
    "    per_device_eval_batch_size: int = 32\n",
    "    auto_find_batch_size: bool = True\n",
    "    logging_dir: str = \"../runs/SubtaskC_baseline/logs\"\n",
    "    logging_steps: int = 10\n",
    "    load_best_model_at_end: bool = True\n",
    "    evaluation_strategy: str = \"epoch\"\n",
    "    save_strategy: str = \"epoch\"\n",
    "    save_total_limit: int = 2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = transformers.HfArgumentParser(\n",
    "    #     (ModelConfig, DatasetConfig, TrainingArgsConfig)\n",
    "    # )\n",
    "    # model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "    # print(\"Model Arguments: \", model_args)\n",
    "    # print(\"Data Arguments: \", data_args)\n",
    "    # print(\"Training Arguments: \", training_args)\n",
    "\n",
    "    # Set seed\n",
    "    transformers.set_seed(42)\n",
    "\n",
    "    model_path = \"allenai/longformer-base-4096\"\n",
    "    # if (\n",
    "    #     training_args.do_eval or training_args.do_predict\n",
    "    # ) and not training_args.do_train:\n",
    "    #     output_dir = training_args.output_dir\n",
    "    #     if not os.path.exists(output_dir):\n",
    "    #         raise ValueError(\n",
    "    #             f\"Output directory ({output_dir}) does not exist. Please train the model first.\"\n",
    "    #         )\n",
    "\n",
    "    #     # Find the best model checkpoint\n",
    "    #     ckpt_paths = sorted(\n",
    "    #         glob.glob(os.path.join(output_dir, \"checkpoint-*\")),\n",
    "    #         key=lambda x: int(x.split(\"-\")[-1]),\n",
    "    #     )\n",
    "\n",
    "    #     if not ckpt_paths:\n",
    "    #         raise ValueError(\n",
    "    #             f\"Output directory ({output_dir}) does not contain any checkpoint. Please train the model first.\"\n",
    "    #         )\n",
    "\n",
    "    #     state = TrainerState.load_from_json(\n",
    "    #         os.path.join(ckpt_paths[-1], \"trainer_state.json\")\n",
    "    #     )\n",
    "    #     best_model_path = state.best_model_checkpoint or model_args.model_path\n",
    "    #     if state.best_model_checkpoint is None:\n",
    "    #         logger.info(\n",
    "    #             \"No best model checkpoint found. Using the default model checkpoint.\"\n",
    "    #         )\n",
    "    #     print(f\"Best model path: {best_model_path}\")\n",
    "    #     model_path = best_model_path\n",
    "\n",
    "    # 4. Load model\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path, num_labels=2, trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    train_set = Semeval_Data(\"../data/original_data/SubtaskC/SubtaskC_train.jsonl\")\n",
    "    dev_set = Semeval_Data(\"../data/original_data/SubtaskC/SubtaskC_dev.jsonl\")\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArgsConfig(),\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=dev_set,\n",
    "        tokenizer=train_set.tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # if training_args.do_train:\n",
    "    logger.info(\"Training...\")\n",
    "    logger.info(\"*** Train Dataset ***\")\n",
    "    logger.info(f\"Number of samples: {len(train_set)}\")\n",
    "    logger.info(\"*** Dev Dataset ***\")\n",
    "    logger.info(f\"Number of samples: {len(dev_set)}\")\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    logger.info(\"Training completed!\")\n",
    "\n",
    "    # if training_args.do_eval:\n",
    "    logger.info(\"Evaluating...\")\n",
    "    logger.info(\"*** Dev Dataset ***\")\n",
    "    logger.info(f\"Number of samples: {len(dev_set)}\")\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "    logger.info(f\"Metrics: {metrics}\")\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    logger.info(\"Evaluation completed!\")\n",
    "\n",
    "    # if training_args.do_predict:\n",
    "    #     test_sets = []\n",
    "    #     for test_file in data_args.test_files:\n",
    "    #         test_set = Semeval_Data(test_file, inference=True)\n",
    "    #         test_sets.append(test_set)\n",
    "    #     logger.info(\"Predicting...\")\n",
    "    #     logger.info(\"*** Test Datasets ***\")\n",
    "    #     logger.info(f\"Number of samples: {len(test_sets)}\")\n",
    "\n",
    "    #     for idx, test_set in enumerate(test_sets):\n",
    "    #         logger.info(f\"Test Dataset {idx + 1}\")\n",
    "    #         logger.info(f\"Number of samples: {len(test_set)}\")\n",
    "\n",
    "    #         predictions, _, _ = trainer.predict(test_set)\n",
    "    #         logger.info(\"Predictions completed!\")\n",
    "\n",
    "    #         df = pd.DataFrame(\n",
    "    #             {\n",
    "    #                 \"id\": [i[\"id\"] for i in test_set],\n",
    "    #                 \"label\": [\n",
    "    #                     get_start_position(\n",
    "    #                         i[0],\n",
    "    #                         np.array(i[1][\"corresponding_word\"]),\n",
    "    #                         token_level=False,\n",
    "    #                     )\n",
    "    #                     for i in list(zip(predictions.argmax(axis=-1), test_set))\n",
    "    #                 ],\n",
    "    #             }\n",
    "    #         )\n",
    "    #         import os\n",
    "\n",
    "    #         file_name = os.path.basename(data_args.test_files[idx])\n",
    "    #         file_dirs = os.path.join(training_args.output_dir, \"predictions\")\n",
    "    #         os.makedirs(file_dirs, exist_ok=True)\n",
    "    #         file_path = os.path.join(file_dirs, file_name)\n",
    "    #         records = df.to_dict(\"records\")\n",
    "    #         with open(file_path, \"w\") as f:\n",
    "    #             for record in records:\n",
    "    #                 f.write(json.dumps(record) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
